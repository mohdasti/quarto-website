[
  {
    "objectID": "skills/index.html",
    "href": "skills/index.html",
    "title": "Technical Skills & Methodologies",
    "section": "",
    "text": "I specialize in a multi-modal approach to understanding human behavior, combining rigorous experimental design with advanced data analysis and physiological measurement. Below is a summary of my core competencies.\nüí° See concrete applications of these skills in my Portfolio case studies.\n\n\nüî¨ Research & Experimental Design\n\nUser Research: End-to-end research planning, psychophysics, usability testing, survey design, A/B testing, user interviews.\nInteraction Design Principles: Applying cognitive science principles to inform the design of intuitive and effective user interfaces, including adaptive systems that respond to user state.\nHuman Factors: Assessing user performance and cognitive load in dual-task and high-stress environments.\nExperiment Programming: Designing and implementing precise behavioral and perceptual tasks using PsychToolbox (MATLAB) and web-based platforms (React/TypeScript).\nPre-registration & Open Science: Developing comprehensive pre-registered study designs with detailed hypotheses, exclusion criteria, and analysis plans. Implementing rigorous experimental protocols with Williams counterbalancing and equivalence testing.\nFitts‚Äôs Law & Human-Computer Interaction: Implementing ISO 9241-9 compliant Fitts‚Äôs Law paradigms for evaluating input modalities, with expertise in projected error calculation and throughput metrics.\n\n\n\n\nüíª Programming & Data Science\n\nLanguages: R (Expert), MATLAB (Expert), TypeScript/JavaScript (Proficient), SQL (Proficient), Python (Familiar), Bash (Familiar).\nWeb Development: React 18, TypeScript, Vite, modern frontend development, event-driven architectures, real-time data synchronization, precise timing control (performance.now() for psychophysics).\nStatistical Modeling: Linear Mixed-Effects Models (LMMs), Bayesian Analysis, Psychometric Function Fitting, Drift-Diffusion Modeling (DDM) with integration of physiological measures (pupillometry).\nMachine Learning: XGBoost, Feature Engineering, Cross-Validation, Hyperparameter Tuning, Predictive Modeling, Real-time ML Pipelines, Model Calibration (Platt scaling), Anomaly Detection (Isolation Forest).\nData Analysis & Visualization (R): Tidyverse (dplyr, ggplot2), R Markdown, Shiny (Interactive Dashboards), gt Tables, Real-time Data Streaming.\nDevelopment & Version Control: Git, GitHub, Google Cloud Platform (GCP), Docker, CI/CD Workflows, Production Deployment (ShinyApps.io, Vercel, Netlify).\n\n\n\n\nüß† Physiological & Neuroimaging Methods\n\nPupillometry: Real-time analysis of pupil dilation as a biomarker for cognitive load and arousal. Computational modeling linking pupillometric dynamics with decision-making processes (DDM integration).\nElectroencephalography (EEG): Collection, preprocessing, and analysis of EEG data, including sleep scoring.\nNeuroimaging Analysis: Analyzing Diffusion MRI (dMRI) data using toolkits such as FSL, QSIPrep, and SPM12.\nGaze Tracking & Eye Movement Analysis: Implementing gaze-based input systems, physiologically-accurate gaze simulation, and analyzing eye movement patterns for cognitive load assessment.\n\n\n\n\n‚ö° Real-time Systems & Production Applications\n\nReal-time Analytics: Multi-modal cognitive state monitoring systems with &lt;1s latency, live data streaming, and interactive dashboards.\nProduction ML: End-to-end ML pipelines with causal feature engineering, model calibration, and deployment-ready applications.\nInteractive Applications: Shiny dashboards with real-time updates, threshold policy sandboxes, and explainable AI interfaces.\nExtended Reality (XR) Platforms: Building research-grade XR experimental platforms with adaptive modality systems, dual input methods (gaze and hand-tracking), real-time performance monitoring, and comprehensive data logging for cognitive load studies.\nSystem Architecture: Docker containerization, CI/CD workflows, and scalable deployment strategies for research and clinical environments. Event-driven architectures with pub/sub systems for inter-component communication.\n\n\n\n\nüè• Applied Research & Industry Experience\n\nBiomedical Engineering: Real-time analytics platforms, surgical performance monitoring, medical device data analysis.\nApplied Psychology: Cognitive state prediction, performance optimization in high-stakes environments.\nHuman-Computer Interaction: Adaptive interface design, modality switching systems, cognitive load-aware UI interventions, and evaluation of input methods using psychophysical paradigms (Fitts‚Äôs Law).\nMixed-Methods Research: Combining behavioral, physiological, and self-report measures (e.g., NASA-TLX) for comprehensive insights into cognitive performance and user experience.\n\n\n\n\nüõ†Ô∏è Project Management & Writing\n\nProject Management: Notion, Slack, Quire.\nScientific & Technical Writing: Quarto, LaTeX, Markdown (Obsidian), MS Office.\nLanguages: Persian (Native), English (Proficient), French (Basic).\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "DOCUMENTATION.html",
    "href": "DOCUMENTATION.html",
    "title": "Technical Documentation",
    "section": "",
    "text": "This document provides detailed technical information about the website structure, customization options, and development workflow.\n\n\n\n\n\nFramework: Quarto (v1.4+)\nStyling: Custom CSS with Bootstrap integration\nIcons: Font Awesome 6.0 + Academicons\nDeployment: Netlify with continuous deployment\nVersion Control: Git with GitHub\n\n\n\n\nquarto-website/\n‚îú‚îÄ‚îÄ _quarto.yml              # Main Quarto configuration\n‚îú‚îÄ‚îÄ _publish.yml             # Publishing and deployment settings\n‚îú‚îÄ‚îÄ index.qmd                # Homepage content\n‚îú‚îÄ‚îÄ cv.qmd                   # CV page\n‚îú‚îÄ‚îÄ about/                   # About section\n‚îÇ   ‚îî‚îÄ‚îÄ index.qmd\n‚îú‚îÄ‚îÄ portfolio/               # Portfolio showcase\n‚îÇ   ‚îî‚îÄ‚îÄ index.qmd\n‚îú‚îÄ‚îÄ publications/            # Research publications\n‚îÇ   ‚îú‚îÄ‚îÄ index.qmd\n‚îÇ   ‚îú‚îÄ‚îÄ peer-reviewed/\n‚îÇ   ‚îî‚îÄ‚îÄ publication[1-8]/\n‚îú‚îÄ‚îÄ projects/                # Case studies and projects\n‚îÇ   ‚îú‚îÄ‚îÄ dual-task-case-study.qmd\n‚îÇ   ‚îú‚îÄ‚îÄ memory-and-meditation.qmd\n‚îÇ   ‚îî‚îÄ‚îÄ surgeon-performance-predict.qmd\n‚îú‚îÄ‚îÄ research/                # Research overview\n‚îÇ   ‚îî‚îÄ‚îÄ index.qmd\n‚îú‚îÄ‚îÄ skills/                  # Skills and methodology\n‚îÇ   ‚îî‚îÄ‚îÄ index.qmd\n‚îú‚îÄ‚îÄ assets/                  # Static assets\n‚îÇ   ‚îú‚îÄ‚îÄ css/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.css         # Main stylesheet\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.css        # Homepage styles\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ publications.css # Publication-specific styles\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ skills.css       # Skills page styles\n‚îÇ   ‚îî‚îÄ‚îÄ listing-default.css  # Default listing styles\n‚îú‚îÄ‚îÄ images/                  # Images and media files\n‚îú‚îÄ‚îÄ CV/                      # CV and resume files\n‚îú‚îÄ‚îÄ _extensions/             # Quarto extensions\n‚îÇ   ‚îî‚îÄ‚îÄ mcanouil/iconify/    # Iconify extension\n‚îî‚îÄ‚îÄ supporting_docs/         # Supporting documents\n\n\n\n\n\n\nMain configuration file controlling:\n\nSite metadata: Title, description, URL\nNavigation: Menu structure and links\nTheme: Visual appearance and styling\nFeatures: Search, social links, footer\nExecution: Code execution settings\n\nKey sections:\nwebsite:\n  title: \"Mohammad Dastgheib\"\n  site-url: https://mdastgheib.com\n  description: \"Vision science researcher...\"\n  navbar: # Navigation menu\n  page-footer: # Footer content and social links\n\nformat:\n  html:\n    theme:\n      light: cosmo\n    css: \n      - assets/css/main.css\n    include-in-header: # External CSS and JS\n\n\n\nDeployment configuration for Netlify:\n- source: project\n  netlify:\n    - id: 676bfb81-9a40-4de6-990b-6fcd2ae00e10\n      url: https://mdastgheib.com\n\n\n\n\n\n\n\n\n\nGlobal styles and variables\nTypography and layout\nComponent-specific styles\nResponsive design rules\n\n\n\n\n\nindex.css: Homepage-specific styling\npublications.css: Publication listing styles\nskills.css: Skills page layout\n\n\n\n\n\nPrimary: #e63946 (Red)\nSecondary: Bootstrap default colors\nBackground: White/light gray\nText: Dark gray/black\n\n\n\n\n\n\n\n:root {\n  --primary-color: #e63946;\n  --secondary-color: #f1faee;\n  --text-color: #1d3557;\n  --background-color: #ffffff;\n}\n\n\n\n\nMobile-first approach\nBootstrap grid system\nCustom breakpoints for academic content\nOptimized for tablets and mobile devices\n\n\n\n\n\n\n\n\n\nMobile: &lt; 768px\nTablet: 768px - 1024px\nDesktop: &gt; 1024px\n\n\n\n\n\nTouch-friendly navigation\nOptimized image sizes\nReadable typography\nSimplified layouts\n\n\n\n\n\n\n\n\nSetup\ngit clone https://github.com/mohdasti/quarto-website.git\ncd quarto-website\nnpm install  # Optional: for package.json dependencies\nDevelopment Server\nquarto preview --watch\n# or\nnpm run dev\nBuild for Production\nquarto render\n# or\nnpm run build\n\n\n\n\n\n\n\nUse YAML front matter for metadata\nMarkdown for content structure\nQuarto-specific features for interactivity\n\n\n\n\n\nImages in images/ directory\nCSS in assets/css/\nOrganized by functionality\n\n\n\n\n\n\n\n\nFeature branches for new content\nPull requests for review\nMain branch for production\nAutomatic deployment via Netlify\n\n\n\n\n\nAdd: for new content\nUpdate: for content changes\nFix: for bug fixes\nStyle: for styling changes\n\n\n\n\n\n\n\n\n\n\n\nBuild Command: quarto render\nPublish Directory: _site\nNode Version: 18.x\n\n\n\n\n\nNo sensitive data required\nPublic repository deployment\n\n\n\n\n\nmdastgheib.com configured\nSSL certificate automatic\nRedirects from www to non-www\n\n\n\n\n\n\nTrigger: Push to main branch\nBuild: Quarto renders site\nDeploy: Netlify publishes to CDN\nCache: Automatic caching for performance\n\n\n\n\n\n\n\n\nWebP format where supported\nResponsive image sizing\nLazy loading for large images\nAlt text for accessibility\n\n\n\n\n\nMinified CSS in production\nCritical CSS inlining\nUnused CSS removal\nFont loading optimization\n\n\n\n\n\nMinimal JavaScript usage\nAsync loading where possible\nNo external dependencies for core functionality\n\n\n\n\n\n\n\n\nMeta tags and descriptions\nOpen Graph tags\nTwitter Card support\nStructured data markup\nXML sitemap generation\n\n\n\n\n\nSemantic HTML structure\nAlt text for images\nKeyboard navigation support\nScreen reader compatibility\nColor contrast compliance\n\n\n\n\n\n\n\n\nCreate .qmd file\n---\ntitle: \"Page Title\"\n---\n\n# Page Content\nUpdate navigation in _quarto.yml\nnavbar:\n  right:\n    - text: \"New Page\"\n      href: new-page.qmd\n\n\n\n\n\nCreate project file in projects/\nUse consistent front matter\nAdd to portfolio if needed\nUpdate navigation if required\n\n\n\n\n\nGlobal styles: Edit assets/css/main.css\nPage-specific: Create new CSS file\nInclude in config: Add to _quarto.yml\n\n\n\n\n\nPublications: Add to publications/\nAbout: Update about/index.qmd\nSkills: Modify skills/index.qmd\nCV: Update cv.qmd and PDF files\n\n\n\n\n\n\n\n\n\n\nCheck Quarto version compatibility\nVerify YAML syntax\nCheck file paths and references\n\n\n\n\n\nClear browser cache\nCheck CSS file paths\nVerify Bootstrap integration\n\n\n\n\n\nCheck Netlify build logs\nVerify build command\nCheck file permissions\n\n\n\n\n\n\n\nquarto check  # Check configuration\nquarto render --debug  # Verbose output\n\n\n\n\nDeveloper tools for CSS debugging\nNetwork tab for asset loading\nConsole for JavaScript errors\n\n\n\n\n\n\n\n\n\nQuarto Documentation\nBootstrap Documentation\nFont Awesome Icons\n\n\n\n\n\nQuarto CLI\nNetlify CLI\nGit\n\n\n\n\n\nSemantic HTML structure\nMobile-first responsive design\nPerformance optimization\nAccessibility compliance\nSEO best practices\n\n\nFor questions or issues, please refer to the Contributing Guidelines or open an issue on GitHub."
  },
  {
    "objectID": "DOCUMENTATION.html#architecture-overview",
    "href": "DOCUMENTATION.html#architecture-overview",
    "title": "Technical Documentation",
    "section": "",
    "text": "Framework: Quarto (v1.4+)\nStyling: Custom CSS with Bootstrap integration\nIcons: Font Awesome 6.0 + Academicons\nDeployment: Netlify with continuous deployment\nVersion Control: Git with GitHub\n\n\n\n\nquarto-website/\n‚îú‚îÄ‚îÄ _quarto.yml              # Main Quarto configuration\n‚îú‚îÄ‚îÄ _publish.yml             # Publishing and deployment settings\n‚îú‚îÄ‚îÄ index.qmd                # Homepage content\n‚îú‚îÄ‚îÄ cv.qmd                   # CV page\n‚îú‚îÄ‚îÄ about/                   # About section\n‚îÇ   ‚îî‚îÄ‚îÄ index.qmd\n‚îú‚îÄ‚îÄ portfolio/               # Portfolio showcase\n‚îÇ   ‚îî‚îÄ‚îÄ index.qmd\n‚îú‚îÄ‚îÄ publications/            # Research publications\n‚îÇ   ‚îú‚îÄ‚îÄ index.qmd\n‚îÇ   ‚îú‚îÄ‚îÄ peer-reviewed/\n‚îÇ   ‚îî‚îÄ‚îÄ publication[1-8]/\n‚îú‚îÄ‚îÄ projects/                # Case studies and projects\n‚îÇ   ‚îú‚îÄ‚îÄ dual-task-case-study.qmd\n‚îÇ   ‚îú‚îÄ‚îÄ memory-and-meditation.qmd\n‚îÇ   ‚îî‚îÄ‚îÄ surgeon-performance-predict.qmd\n‚îú‚îÄ‚îÄ research/                # Research overview\n‚îÇ   ‚îî‚îÄ‚îÄ index.qmd\n‚îú‚îÄ‚îÄ skills/                  # Skills and methodology\n‚îÇ   ‚îî‚îÄ‚îÄ index.qmd\n‚îú‚îÄ‚îÄ assets/                  # Static assets\n‚îÇ   ‚îú‚îÄ‚îÄ css/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.css         # Main stylesheet\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.css        # Homepage styles\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ publications.css # Publication-specific styles\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ skills.css       # Skills page styles\n‚îÇ   ‚îî‚îÄ‚îÄ listing-default.css  # Default listing styles\n‚îú‚îÄ‚îÄ images/                  # Images and media files\n‚îú‚îÄ‚îÄ CV/                      # CV and resume files\n‚îú‚îÄ‚îÄ _extensions/             # Quarto extensions\n‚îÇ   ‚îî‚îÄ‚îÄ mcanouil/iconify/    # Iconify extension\n‚îî‚îÄ‚îÄ supporting_docs/         # Supporting documents"
  },
  {
    "objectID": "DOCUMENTATION.html#configuration-files",
    "href": "DOCUMENTATION.html#configuration-files",
    "title": "Technical Documentation",
    "section": "",
    "text": "Main configuration file controlling:\n\nSite metadata: Title, description, URL\nNavigation: Menu structure and links\nTheme: Visual appearance and styling\nFeatures: Search, social links, footer\nExecution: Code execution settings\n\nKey sections:\nwebsite:\n  title: \"Mohammad Dastgheib\"\n  site-url: https://mdastgheib.com\n  description: \"Vision science researcher...\"\n  navbar: # Navigation menu\n  page-footer: # Footer content and social links\n\nformat:\n  html:\n    theme:\n      light: cosmo\n    css: \n      - assets/css/main.css\n    include-in-header: # External CSS and JS\n\n\n\nDeployment configuration for Netlify:\n- source: project\n  netlify:\n    - id: 676bfb81-9a40-4de6-990b-6fcd2ae00e10\n      url: https://mdastgheib.com"
  },
  {
    "objectID": "DOCUMENTATION.html#styling-and-theming",
    "href": "DOCUMENTATION.html#styling-and-theming",
    "title": "Technical Documentation",
    "section": "",
    "text": "Global styles and variables\nTypography and layout\nComponent-specific styles\nResponsive design rules\n\n\n\n\n\nindex.css: Homepage-specific styling\npublications.css: Publication listing styles\nskills.css: Skills page layout\n\n\n\n\n\nPrimary: #e63946 (Red)\nSecondary: Bootstrap default colors\nBackground: White/light gray\nText: Dark gray/black\n\n\n\n\n\n\n\n:root {\n  --primary-color: #e63946;\n  --secondary-color: #f1faee;\n  --text-color: #1d3557;\n  --background-color: #ffffff;\n}\n\n\n\n\nMobile-first approach\nBootstrap grid system\nCustom breakpoints for academic content\nOptimized for tablets and mobile devices"
  },
  {
    "objectID": "DOCUMENTATION.html#responsive-design-1",
    "href": "DOCUMENTATION.html#responsive-design-1",
    "title": "Technical Documentation",
    "section": "",
    "text": "Mobile: &lt; 768px\nTablet: 768px - 1024px\nDesktop: &gt; 1024px\n\n\n\n\n\nTouch-friendly navigation\nOptimized image sizes\nReadable typography\nSimplified layouts"
  },
  {
    "objectID": "DOCUMENTATION.html#development-workflow",
    "href": "DOCUMENTATION.html#development-workflow",
    "title": "Technical Documentation",
    "section": "",
    "text": "Setup\ngit clone https://github.com/mohdasti/quarto-website.git\ncd quarto-website\nnpm install  # Optional: for package.json dependencies\nDevelopment Server\nquarto preview --watch\n# or\nnpm run dev\nBuild for Production\nquarto render\n# or\nnpm run build\n\n\n\n\n\n\n\nUse YAML front matter for metadata\nMarkdown for content structure\nQuarto-specific features for interactivity\n\n\n\n\n\nImages in images/ directory\nCSS in assets/css/\nOrganized by functionality\n\n\n\n\n\n\n\n\nFeature branches for new content\nPull requests for review\nMain branch for production\nAutomatic deployment via Netlify\n\n\n\n\n\nAdd: for new content\nUpdate: for content changes\nFix: for bug fixes\nStyle: for styling changes"
  },
  {
    "objectID": "DOCUMENTATION.html#deployment",
    "href": "DOCUMENTATION.html#deployment",
    "title": "Technical Documentation",
    "section": "",
    "text": "Build Command: quarto render\nPublish Directory: _site\nNode Version: 18.x\n\n\n\n\n\nNo sensitive data required\nPublic repository deployment\n\n\n\n\n\nmdastgheib.com configured\nSSL certificate automatic\nRedirects from www to non-www\n\n\n\n\n\n\nTrigger: Push to main branch\nBuild: Quarto renders site\nDeploy: Netlify publishes to CDN\nCache: Automatic caching for performance"
  },
  {
    "objectID": "DOCUMENTATION.html#performance-optimization",
    "href": "DOCUMENTATION.html#performance-optimization",
    "title": "Technical Documentation",
    "section": "",
    "text": "WebP format where supported\nResponsive image sizing\nLazy loading for large images\nAlt text for accessibility\n\n\n\n\n\nMinified CSS in production\nCritical CSS inlining\nUnused CSS removal\nFont loading optimization\n\n\n\n\n\nMinimal JavaScript usage\nAsync loading where possible\nNo external dependencies for core functionality"
  },
  {
    "objectID": "DOCUMENTATION.html#seo-and-accessibility",
    "href": "DOCUMENTATION.html#seo-and-accessibility",
    "title": "Technical Documentation",
    "section": "",
    "text": "Meta tags and descriptions\nOpen Graph tags\nTwitter Card support\nStructured data markup\nXML sitemap generation\n\n\n\n\n\nSemantic HTML structure\nAlt text for images\nKeyboard navigation support\nScreen reader compatibility\nColor contrast compliance"
  },
  {
    "objectID": "DOCUMENTATION.html#customization-guide",
    "href": "DOCUMENTATION.html#customization-guide",
    "title": "Technical Documentation",
    "section": "",
    "text": "Create .qmd file\n---\ntitle: \"Page Title\"\n---\n\n# Page Content\nUpdate navigation in _quarto.yml\nnavbar:\n  right:\n    - text: \"New Page\"\n      href: new-page.qmd\n\n\n\n\n\nCreate project file in projects/\nUse consistent front matter\nAdd to portfolio if needed\nUpdate navigation if required\n\n\n\n\n\nGlobal styles: Edit assets/css/main.css\nPage-specific: Create new CSS file\nInclude in config: Add to _quarto.yml\n\n\n\n\n\nPublications: Add to publications/\nAbout: Update about/index.qmd\nSkills: Modify skills/index.qmd\nCV: Update cv.qmd and PDF files"
  },
  {
    "objectID": "DOCUMENTATION.html#troubleshooting",
    "href": "DOCUMENTATION.html#troubleshooting",
    "title": "Technical Documentation",
    "section": "",
    "text": "Check Quarto version compatibility\nVerify YAML syntax\nCheck file paths and references\n\n\n\n\n\nClear browser cache\nCheck CSS file paths\nVerify Bootstrap integration\n\n\n\n\n\nCheck Netlify build logs\nVerify build command\nCheck file permissions\n\n\n\n\n\n\n\nquarto check  # Check configuration\nquarto render --debug  # Verbose output\n\n\n\n\nDeveloper tools for CSS debugging\nNetwork tab for asset loading\nConsole for JavaScript errors"
  },
  {
    "objectID": "DOCUMENTATION.html#resources",
    "href": "DOCUMENTATION.html#resources",
    "title": "Technical Documentation",
    "section": "",
    "text": "Quarto Documentation\nBootstrap Documentation\nFont Awesome Icons\n\n\n\n\n\nQuarto CLI\nNetlify CLI\nGit\n\n\n\n\n\nSemantic HTML structure\nMobile-first responsive design\nPerformance optimization\nAccessibility compliance\nSEO best practices\n\n\nFor questions or issues, please refer to the Contributing Guidelines or open an issue on GitHub."
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Contributing to Mohammad Dastgheib‚Äôs Personal Website",
    "section": "",
    "text": "Thank you for your interest in contributing to this project! This document provides guidelines and information for contributors.\n\n\n\n\nIf you find a bug or have a suggestion for improvement:\n\nCheck if the issue already exists in the Issues section\nCreate a new issue with:\n\nClear, descriptive title\nDetailed description of the problem or suggestion\nSteps to reproduce (for bugs)\nExpected vs.¬†actual behavior\nScreenshots (if applicable)\n\n\n\n\n\n\nFork the repository\ngit clone https://github.com/your-username/quarto-website.git\ncd quarto-website\nCreate a feature branch\ngit checkout -b feature/your-feature-name\nMake your changes\n\nFollow the existing code style and structure\nTest your changes locally using quarto preview\nEnsure the site builds without errors\n\nCommit your changes\ngit add .\ngit commit -m \"Add: brief description of your changes\"\nPush to your fork\ngit push origin feature/your-feature-name\nCreate a Pull Request\n\nProvide a clear title and description\nReference any related issues\nInclude screenshots for visual changes\n\n\n\n\n\n\n\n\n\nMarkdown: Use consistent formatting and clear structure\nCSS: Follow existing naming conventions and organization\nImages: Optimize images for web use\nContent: Maintain professional, academic tone\n\n\n\n\n\nKeep related files together\nUse descriptive file and directory names\nFollow the existing project structure\n\n\n\n\nBefore submitting changes:\n\nLocal Testing\nquarto preview --watch\nBuild Testing\nquarto render\nCross-browser Testing\n\nTest on different browsers and devices\nEnsure responsive design works correctly\n\n\n\n\n\n\n\n\n\nUse clear, professional language\nMaintain academic tone appropriate for research content\nProofread for grammar and spelling\nKeep content concise and focused\n\n\n\n\n\nUse high-quality, relevant images\nOptimize file sizes for web performance\nInclude appropriate alt text for accessibility\nMaintain consistent aspect ratios where possible\n\n\n\n\n\nEnsure accuracy of research information\nCite sources appropriately\nMaintain consistency with CV and publications\nUpdate dates and information as needed\n\n\n\n\n\n\n\n\nPublications: Add new research papers or presentations\nProjects: Update case studies or add new projects\nAbout: Update biographical information or research focus\nSkills: Add new methodologies or technical skills\n\n\n\n\n\nStyling: Enhance CSS or visual design\nFunctionality: Add interactive features or improve existing ones\nPerformance: Optimize loading times or responsiveness\nAccessibility: Improve site accessibility and usability\n\n\n\n\n\nREADME: Improve project documentation\nComments: Add helpful comments to code\nGuides: Create tutorials or setup guides\n\n\n\n\n\n\nReview Process\n\nAll PRs will be reviewed by the maintainer\nFeedback will be provided for improvements\nChanges may be requested before merging\n\nApproval Criteria\n\nCode follows project guidelines\nChanges work as intended\nNo breaking changes to existing functionality\nAppropriate documentation updates\n\nMerge Process\n\nPRs will be merged after approval\nChanges will be deployed automatically via Netlify\nContributors will be credited in commit history\n\n\n\n\n\nWhen reporting bugs, please include:\n\nEnvironment: Operating system, browser, Quarto version\nSteps to Reproduce: Clear, numbered steps\nExpected Behavior: What should happen\nActual Behavior: What actually happens\nScreenshots: Visual evidence of the issue\nError Messages: Any console errors or warnings\n\n\n\n\nFor new features, please provide:\n\nUse Case: Why this feature would be valuable\nProposed Solution: How you envision it working\nAlternatives: Other approaches you‚Äôve considered\nAdditional Context: Any relevant background information\n\n\n\n\nIf you have questions about contributing:\n\nEmail: mdast003@ucr.edu\nGitHub Issues: Use the Issues section for public discussions\nLinkedIn: linkedin.com/in/mdastgheib\n\n\n\n\nContributors will be recognized in:\n\nCommit history and pull request comments\nProject documentation (if significant contributions)\nPersonal acknowledgments for major contributions\n\n\n\n\nBy contributing to this project, you agree that your contributions will be licensed under the same MIT License that covers the project.\n\nThank you for helping make this website better! Your contributions are greatly appreciated."
  },
  {
    "objectID": "CONTRIBUTING.html#how-to-contribute",
    "href": "CONTRIBUTING.html#how-to-contribute",
    "title": "Contributing to Mohammad Dastgheib‚Äôs Personal Website",
    "section": "",
    "text": "If you find a bug or have a suggestion for improvement:\n\nCheck if the issue already exists in the Issues section\nCreate a new issue with:\n\nClear, descriptive title\nDetailed description of the problem or suggestion\nSteps to reproduce (for bugs)\nExpected vs.¬†actual behavior\nScreenshots (if applicable)\n\n\n\n\n\n\nFork the repository\ngit clone https://github.com/your-username/quarto-website.git\ncd quarto-website\nCreate a feature branch\ngit checkout -b feature/your-feature-name\nMake your changes\n\nFollow the existing code style and structure\nTest your changes locally using quarto preview\nEnsure the site builds without errors\n\nCommit your changes\ngit add .\ngit commit -m \"Add: brief description of your changes\"\nPush to your fork\ngit push origin feature/your-feature-name\nCreate a Pull Request\n\nProvide a clear title and description\nReference any related issues\nInclude screenshots for visual changes"
  },
  {
    "objectID": "CONTRIBUTING.html#development-guidelines",
    "href": "CONTRIBUTING.html#development-guidelines",
    "title": "Contributing to Mohammad Dastgheib‚Äôs Personal Website",
    "section": "",
    "text": "Markdown: Use consistent formatting and clear structure\nCSS: Follow existing naming conventions and organization\nImages: Optimize images for web use\nContent: Maintain professional, academic tone\n\n\n\n\n\nKeep related files together\nUse descriptive file and directory names\nFollow the existing project structure\n\n\n\n\nBefore submitting changes:\n\nLocal Testing\nquarto preview --watch\nBuild Testing\nquarto render\nCross-browser Testing\n\nTest on different browsers and devices\nEnsure responsive design works correctly"
  },
  {
    "objectID": "CONTRIBUTING.html#content-guidelines",
    "href": "CONTRIBUTING.html#content-guidelines",
    "title": "Contributing to Mohammad Dastgheib‚Äôs Personal Website",
    "section": "",
    "text": "Use clear, professional language\nMaintain academic tone appropriate for research content\nProofread for grammar and spelling\nKeep content concise and focused\n\n\n\n\n\nUse high-quality, relevant images\nOptimize file sizes for web performance\nInclude appropriate alt text for accessibility\nMaintain consistent aspect ratios where possible\n\n\n\n\n\nEnsure accuracy of research information\nCite sources appropriately\nMaintain consistency with CV and publications\nUpdate dates and information as needed"
  },
  {
    "objectID": "CONTRIBUTING.html#types-of-contributions",
    "href": "CONTRIBUTING.html#types-of-contributions",
    "title": "Contributing to Mohammad Dastgheib‚Äôs Personal Website",
    "section": "",
    "text": "Publications: Add new research papers or presentations\nProjects: Update case studies or add new projects\nAbout: Update biographical information or research focus\nSkills: Add new methodologies or technical skills\n\n\n\n\n\nStyling: Enhance CSS or visual design\nFunctionality: Add interactive features or improve existing ones\nPerformance: Optimize loading times or responsiveness\nAccessibility: Improve site accessibility and usability\n\n\n\n\n\nREADME: Improve project documentation\nComments: Add helpful comments to code\nGuides: Create tutorials or setup guides"
  },
  {
    "objectID": "CONTRIBUTING.html#pull-request-process",
    "href": "CONTRIBUTING.html#pull-request-process",
    "title": "Contributing to Mohammad Dastgheib‚Äôs Personal Website",
    "section": "",
    "text": "Review Process\n\nAll PRs will be reviewed by the maintainer\nFeedback will be provided for improvements\nChanges may be requested before merging\n\nApproval Criteria\n\nCode follows project guidelines\nChanges work as intended\nNo breaking changes to existing functionality\nAppropriate documentation updates\n\nMerge Process\n\nPRs will be merged after approval\nChanges will be deployed automatically via Netlify\nContributors will be credited in commit history"
  },
  {
    "objectID": "CONTRIBUTING.html#bug-reports",
    "href": "CONTRIBUTING.html#bug-reports",
    "title": "Contributing to Mohammad Dastgheib‚Äôs Personal Website",
    "section": "",
    "text": "When reporting bugs, please include:\n\nEnvironment: Operating system, browser, Quarto version\nSteps to Reproduce: Clear, numbered steps\nExpected Behavior: What should happen\nActual Behavior: What actually happens\nScreenshots: Visual evidence of the issue\nError Messages: Any console errors or warnings"
  },
  {
    "objectID": "CONTRIBUTING.html#feature-requests",
    "href": "CONTRIBUTING.html#feature-requests",
    "title": "Contributing to Mohammad Dastgheib‚Äôs Personal Website",
    "section": "",
    "text": "For new features, please provide:\n\nUse Case: Why this feature would be valuable\nProposed Solution: How you envision it working\nAlternatives: Other approaches you‚Äôve considered\nAdditional Context: Any relevant background information"
  },
  {
    "objectID": "CONTRIBUTING.html#contact",
    "href": "CONTRIBUTING.html#contact",
    "title": "Contributing to Mohammad Dastgheib‚Äôs Personal Website",
    "section": "",
    "text": "If you have questions about contributing:\n\nEmail: mdast003@ucr.edu\nGitHub Issues: Use the Issues section for public discussions\nLinkedIn: linkedin.com/in/mdastgheib"
  },
  {
    "objectID": "CONTRIBUTING.html#recognition",
    "href": "CONTRIBUTING.html#recognition",
    "title": "Contributing to Mohammad Dastgheib‚Äôs Personal Website",
    "section": "",
    "text": "Contributors will be recognized in:\n\nCommit history and pull request comments\nProject documentation (if significant contributions)\nPersonal acknowledgments for major contributions"
  },
  {
    "objectID": "CONTRIBUTING.html#license",
    "href": "CONTRIBUTING.html#license",
    "title": "Contributing to Mohammad Dastgheib‚Äôs Personal Website",
    "section": "",
    "text": "By contributing to this project, you agree that your contributions will be licensed under the same MIT License that covers the project.\n\nThank you for helping make this website better! Your contributions are greatly appreciated."
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "About Me",
    "section": "",
    "text": "I am a cognitive neuroscientist and human factors researcher driven by a fundamental question: Why do we make the decisions we do, especially under pressure? My work sits at the intersection of psychology and technology, where I use a multi-modal approach to deconstruct the hidden cognitive processes behind human behavior.\nMy core research focuses on how factors like aging, physical stress, and physiological arousal impact our ability to perceive, learn, and remember. To get at the ‚Äúwhy‚Äù behind performance, I go beyond simple behavioral metrics, specializing in methodologies like pupillometry to get a real-time, objective measure of cognitive load and computational modeling to isolate the subcomponents of decision-making.\nMy goal is to translate these deep scientific insights into practical applications. I am passionate about using this knowledge to help design safer, more intuitive, and more inclusive technologies."
  },
  {
    "objectID": "about/index.html#education",
    "href": "about/index.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\n\n\n\n\n\n\n\n\n\nPhD in Psychology and Cognitive Neuroscience\nUniversity of California, Riverside\n2021 ‚Äì 2026 (Expected)\n\n\n\n\n\n\n\n\n\n\n\n\nM.Sc. in Psychology\n\nQueen‚Äôs University\n2017 ‚Äì 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\nHon.¬†B.Sc. in Biological Sciences & Psychology\n\nYork University\n2013 ‚Äì 2017"
  },
  {
    "objectID": "about/index.html#industry-experience",
    "href": "about/index.html#industry-experience",
    "title": "About Me",
    "section": "Industry Experience",
    "text": "Industry Experience\n\n\n\n\n\nResearch Assistant I\nSurgical Safety Technologies (SST) | Toronto, ON | 2021"
  },
  {
    "objectID": "projects/archive/surgeon-performance-predict-backup.html",
    "href": "projects/archive/surgeon-performance-predict-backup.html",
    "title": "The Surgeon‚Äôs ‚ÄòCognitive Black Box‚Äô",
    "section": "",
    "text": "üöÄ The Vision: From Post-Op Review to Proactive Support\n\n‚ÄúDuring my time as an AI Annotator at Surgical Safety Technologies (SST), I had a firsthand view of how their groundbreaking ‚ÄòOR Black Box‚Äô captures the complex dynamics of the operating room to improve patient outcomes. This experience solidified my understanding of the immense value in data-driven clinical insights. It also highlighted the next critical frontier: moving beyond analyzing what happened to understanding the surgeon‚Äôs cognitive state‚Äîthe why behind their actions.‚Äù\n\nThis project is my answer to that challenge. I developed a proof-of-concept for a ‚ÄúCognitive Black Box‚Äù‚Äîan end-to-end analytics platform that predicts a surgeon‚Äôs cognitive state in real-time. By fusing my PhD research on the cognitive neuroscience of effort with my industry experience, this case study demonstrates a tangible solution for moving from post-operative review to proactive, intraoperative support, enhancing both patient safety and surgeon well-being.\n\n\n\n\n\n\n\nA mockup of a surgical console screen displaying a time-series plot of the surgeon‚Äôs pupil dilation and grip force variability, indicating their cognitive state during a procedure.\n\n\n\n\n\nüß† The Scientific Framework: My Research in Action\nThis project is an application of my PhD research, which provides the theoretical engine to model the underlying mechanisms of performance degradation under pressure.\n\nAdaptive Gain Theory (AGT)Resource Competition TheoryKey Concepts & Terminology\n\n\nAGT provides the physiological why. The brain‚Äôs arousal system (specifically the LC-NE system) acts like a ‚Äúvolume knob,‚Äù adjusting neural gain to enhance important signals and suppress noise. My research shows that under the high combined effort typical of surgery, this system can become dysregulated, a phenomenon I can model and predict using pupillometry as a direct, non-invasive biomarker of this process.\n Caption: The inverted-U relationship between arousal and performance, central to Adaptive Gain Theory. My system is designed to identify when a surgeon moves past the optimal point and into a state of impaired performance due to excessive cognitive load.\n\n\nThis framework explains what happens when a surgeon performs a physically demanding action (like sustained retraction, mirroring my 40% MVC research) while making a high-stakes cognitive judgment. These tasks compete for the same finite pool of mental resources. My model is designed to detect when this competition leads to performance-impairing cognitive overload.\n\n\nA brief glossary of the core concepts from my research that power this project.\n\nPupillometry: The measurement of pupil diameter. I use it as a precise, non-invasive biomarker of cognitive effort and arousal, as it is tightly linked to activity in the brain‚Äôs Locus Coeruleus-Norepinephrine (LC-NE) system.\nTonic vs.¬†Phasic Arousal: These are two distinct modes of the arousal system that I model with my features:\n\nTonic Arousal (tonic_pupil_level_30s): Refers to the slow-moving, baseline level of alertness over a longer period (tens of seconds). It reflects the surgeon‚Äôs overall engagement and processing load.\nPhasic Arousal (phasic_pupil_change_5s): Refers to the rapid, transient bursts of arousal in response to a specific event (e.g., making a critical suture). It reflects the momentary deployment of focused mental effort.\n\nGrip Force Variability (grip_force_variability_15s): A novel feature I engineered for this project. It‚Äôs based on the hypothesis that maintaining a steady isometric muscle contraction requires constant attentional control. Therefore, an increase in the variability (i.e., noise) of the grip force signal can serve as a proxy for a lapse in sustained attention.\nXGBoost (Extreme Gradient Boosting): The machine learning algorithm I chose for the classification task. It is a high-performance, industry-standard model known for its accuracy and its ability to handle complex, non-linear relationships in data.\nFeature Engineering: The process of transforming raw sensor data into meaningful variables that machine learning algorithms can use effectively. My domain expertise in cognitive neuroscience guided the creation of theory-driven features rather than generic statistical measures.\nCross-Validation & Hyperparameter Tuning: Rigorous methods to ensure model reliability. Cross-validation tests the model on unseen data subsets, while hyperparameter tuning optimizes the model‚Äôs configuration for best performance.\n\n\n\n\n\n\n\n‚öôÔ∏è The Machine Learning Pipeline: From Raw Data to Actionable Insight\nI designed an end-to-end pipeline to simulate and process multimodal data, engineer theoretically-grounded features, and train a predictive model.\n\n1. Data Simulation2. Feature Engineering3. Modeling & Explainability (XAI)\n\n\nTo build this proof-of-concept, I simulated a realistic, second-by-second data stream from a 3-hour surgical procedure. The dataset includes:\n\nPhysiological Data: pupil_diameter_mm - continuous pupillometry measurements\nMotor Control Data: grip_force_newtons - surgical instrument grip pressure\nBehavioral Data: instrument_tremor_hz- high-frequency tremor measurements\n\nTarget Variable: cognitive_state (‚ÄúOptimal‚Äù, ‚ÄúHigh Load‚Äù, ‚ÄúFatigued‚Äù, ‚ÄúAttentional Lapse‚Äù)\n\nThe simulation creates 32,400 observations (3 surgeons √ó 10,800 seconds) with realistic temporal dynamics and state transitions based on surgical workflow patterns.\n\n\nThis is where my domain expertise becomes critical. I created novel, theory-driven features:\n\ntonic_pupil_level_30s: A 30-second rolling average of pupil diameter, reflecting baseline arousal and overall cognitive load.\nphasic_pupil_change_5s: An event-related dilation metric capturing rapid pupil changes from a 5-second baseline, reflecting the brain‚Äôs adaptive gain response to critical surgical events.\ngrip_force_variability_15s: A novel metric I developed for this project. It calculates the 15-second rolling standard deviation of instrument grip force, based on my hypothesis, grounded in dual-task literature, that increased variability in fine motor control serves as a proxy for attentional lapses.\ntremor_trend_10s: A 10-second rolling mean of instrument tremor, capturing fine motor control degradation.\npupil_diameter_lag_5s: Temporal context feature providing the pupil state from 5 seconds prior.\n\n\n\nI trained an XGBoost Classifier with hyperparameter tuning using 3-fold cross-validation‚Äîan industry-standard, high-performance model‚Äîto predict the surgeon‚Äôs cognitive state. The model achieves:\n\nOverall Accuracy: 99.58%\nCohen‚Äôs Kappa: 0.993\nCross-Validation: Robust performance across folds with grid search optimization\n\nTo ensure the model is interpretable and trustworthy for clinical stakeholders, I implemented feature importance analysis and dynamic explanations that show which physiological signals are driving each prediction in real-time.\n\n\n\n\n\n\n\nFeature importance from the trained XGBoost model showing the relative predictive power of each engineered feature.\n\n\n\n\n\n\n\n\n‚ú® The Result: A Real-Time Analytics Dashboard\nThe final output is a proof-of-concept dashboard built in R Shiny. It simulates a live view of the surgeon‚Äôs cognitive state and provides clear, interpretable alerts with two main interfaces:\n\nLive Surgical DashboardML Model Diagnostics\n\n\nThe primary interface provides real-time monitoring during surgery with an intuitive, clinical-focused design.\n\n\n\n\n\n\n\nLive Surgical Dashboard showing real-time pupil diameter and grip force monitoring with cognitive state prediction and dynamic clinical interpretations.\n\n\nKey Features:\n\nReal-time sensor plots: Pupil diameter and grip force visualized with human-readable time formatting\nCognitive state spectrum: Dynamic dial showing current state on a visual spectrum\nProgress tracking: Video-style progress bar with accurate time remaining\nDynamic ‚ÄúWhy‚Äù panel: Data-driven clinical interpretations that update based on live feature values\nSpeed controls: Simulation can run at 1x, 10x, 50x, or 100x speed for demos\n\n\n\nThe technical interface provides transparency into the machine learning model‚Äôs decision-making process.\n\n\n\n\n\n\n\nML Model Diagnostics panel showing prediction probabilities, live feature values, and feature importance visualization.\n\n\nTechnical Features:\n\nPrediction probabilities: Live confidence scores for all four cognitive states\nFeature values table: Real-time display of all engineered features driving predictions\nFeature importance: Static visualization showing which features matter most to the model\n\n\n\n\nInnovation Highlight: Data-Driven Explanations The most innovative feature is the dynamic ‚ÄúWhy‚Äù panel that doesn‚Äôt just show generic text, but reports the actual feature values driving each prediction (e.g., ‚ÄúHigh Grip Force Variability (2.31 N)‚Äù or ‚ÄúElevated Tonic Pupil Level (4.2 mm)‚Äù), building trust through transparency.\n\n\n\nüöÄ Applications: Enhancing the da Vinci Surgical System\nThe true power of this research is its direct applicability to high-stakes environments. While the methodology is versatile, this case study focuses on a specific, high-impact application: enhancing the capabilities of Intuitive‚Äôs da Vinci surgical systems.\nThe da Vinci platform provides unparalleled robotic control and visualization but currently lacks objective, real-time monitoring of the surgeon‚Äôs cognitive state. My ‚ÄúCognitive Black Box‚Äù is designed to integrate seamlessly with the existing da Vinci ecosystem to fill this critical gap, transforming the surgeon‚Äôs console into a cognitively-aware command center.\n\nüè• High-Stakes Medicine: The Cognitively-Aware Surgical Console\nProblem: A surgeon‚Äôs performance can be compromised by fatigue and high cognitive load long before they are consciously aware of it. The da Vinci system logs instrument data, but it cannot see the surgeon‚Äôs mental state.\nMy Solution: Integrate my real-time cognitive state analytics directly into the da Vinci surgeon console.\n1. Integration with the Surgeon Console Viewfinder:\n\nExisting Feature: The da Vinci surgeon console provides a high-definition, 3D view of the surgical site.\nMy Enhancement: I propose a minimalist Heads-Up Display (HUD) overlay at the edge of the viewfinder. This HUD would display a simple, color-coded Cognitive State Indicator (CSI). It would remain a calm green during ‚ÄúOptimal‚Äù states, turn yellow during ‚ÄúHigh Load,‚Äù and provide a subtle, non-distracting red pulse during a predicted ‚ÄúAttentional Lapse.‚Äù This provides critical feedback without diverting the surgeon‚Äôs focus.\n\n2. Leveraging da Vinci‚Äôs Built-in Data Streams:\n\nExisting Feature: Da Vinci systems can already record instrument and event data. My work at SST involved annotating this type of procedural video data.\nMy Enhancement: My system would tap into these existing data streams. The grip_force_variability feature I developed would be calculated directly from the force sensors in the master controllers (the surgeon‚Äôs hand controls). The phasic_pupil_response would be timed to critical events logged by the system, such as instrument activation or error alerts. This isn‚Äôt a new set of sensors; it‚Äôs a smarter use of the data already being generated.\n\n3. Enhancing Post-Operative Debriefing with ‚ÄúSimulated Eye View‚Äù:\n\nExisting Feature: Intuitive provides products like the ‚ÄúSimulated Eye View‚Äù for post-operative review and training.\nMy Enhancement: I propose augmenting these recordings with a synchronized timeline of the surgeon‚Äôs predicted cognitive state. Trainees could see exactly when and why a period of high cognitive load occurred, correlating it with specific surgical steps. The ‚ÄúWhy‚Äù panel from my dashboard would provide objective, data-driven talking points for the debriefing session, moving beyond subjective recall.\n\n\n\n\n\nüìö Project Artifacts & Technical Details\n\nCode & RepositoryModel PerformanceResearch Foundation\n\n\n\nGitHub Repository: View the complete source code, data pipeline, and interactive dashboard\nTech Stack: R, Shiny, XGBoost, tidyverse, ggplot2, DT\nDevelopment Approach: Modular pipeline with separate scripts for data simulation, feature engineering, and model training\nReproducibility: All code includes seed setting and comprehensive logging for transparent replication\n\n\n\nTraining Results:\n\nDataset: 32,400 observations across 3 simulated surgeons\nFeatures: 5 engineered features from 3 raw sensor streams\nAlgorithm: XGBoost with 3-fold cross-validation hyperparameter tuning\nAccuracy: 99.58% overall accuracy with Œ∫ = 0.993\n\nPer-Class Performance:\n\nOptimal State: 100% sensitivity, 100% specificity\nHigh Load: 99.9% sensitivity, 100% specificity\n\nFatigued: 99.9% sensitivity, 99.4% specificity\nAttentional Lapse: 25% sensitivity, 100% specificity*\n\nAttentional lapses are rare events (0.4% prevalence), where high specificity is prioritized to avoid false alarms.\n\n\n\nGrant Proposal: Read the peer-reviewed research proposal providing the theoretical foundation\nIndustry Context: Inspired by work as AI Annotator at Surgical Safety Technologies (SST)\nAcademic Integration: Direct application of PhD research on cognitive neuroscience of effort and Adaptive Gain Theory\n\n\n\n\n\n\n\nüéØ Impact & Next Steps\nImmediate Applications:\n\nSurgical Training: Objective assessment of trainee cognitive load during skill development, reducing time-to-proficiency and identifying trainees who may require additional support\nQuality Improvement: Data-driven insights into when and why surgical performance degrades, potentially reducing intraoperative errors by flagging high-risk cognitive states\nResearch Platform: Foundational system for studying cognitive load in high-stakes environments\n\nFuture Development:\n\nHardware Integration: Connect with real pupillometry and force sensor systems\nClinical Validation: Partner with surgical training centers for real-world testing\n\nMulti-Modal Expansion: Incorporate additional physiological signals I have experience with, such as Heart Rate Variability (HRV), EEG, and cortisol\nTeam Monitoring: Extend to monitor multiple team members simultaneously\n\nThis proof-of-concept demonstrates the feasibility of real-time cognitive monitoring in surgical environments, bridging fundamental neuroscience research with practical clinical applications.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/memory-and-meditation.html",
    "href": "projects/memory-and-meditation.html",
    "title": "Case Study: Optimizing Learning with Cognitive States",
    "section": "",
    "text": "üß† Optimizing Learning: A Deep Dive into the Cognitive States that Boost Memory\n\n\nüìä Executive Summary / TL;DR\n\nThe Problem: Companies build tools to help users learn and be productive but lack clarity on how different mental states (like napping or meditating) influence the brain‚Äôs ability to retain factual versus physical memories. This uncertainty can result in inefficiencies, diminished user performance, and wasted investments in training programs or wellness initiatives.\nMy Action: I designed and executed an end-to-end research study involving 60+ participants, employing a mixed-methods approach with behavioral tasks (word-pair recall, a physical maze game), physiological EEG recordings, and self-report questionnaires.\nThe Result: I discovered that mindfulness meditation significantly improved factual memory retention. The most surprising discovery was that while naps are restorative, deep sleep can temporarily impair physical skills due to sleep inertia‚Äîa critical insight for products or services targeting immediate post-rest performance.\n\n\n\n\nüéØ The Business Problem / The Challenge\nProduct teams in e-learning, corporate training, and wellness often design experiences without clear evidence on how users‚Äô cognitive states impact their ability to learn. Is a power nap or meditation more effective for mastering a new software skill or physical task? This study addressed these questions by exploring how rest, naps, and meditation specifically influence:\n\nDeclarative Memory: Crucial for retaining facts and information.\nProcedural Memory: Essential for acquiring new physical skills.\n\n\n\n\nüßë‚Äçüî¨ My Role & Responsibilities\n\nLead Researcher: Oversaw the entire research process from ideation to completion.\nProject Manager: Scoped the study, managed timelines, coordinated 60+ participants over multiple sessions, and ensured seamless execution.\nMentor & Team Lead: Guided and trained a team of three student researchers (including one undergraduate capstone project) on experimental protocols, data collection techniques, and research ethics.\nResearch Designer: Developed the research protocols, memory task stimuli, and selected EEG hardware and analytical tools.\nData Scientist: Performed all data preprocessing, cleaning, and advanced statistical analyses utilizing R and Bayesian methodologies.\nCommunicator: Presented findings clearly to interdisciplinary stakeholders and authored a peer-reviewed perspective piece, translating complex results into actionable recommendations for the broader scientific community.\n\n\n\n\nüî¨ The Approach: A 3-Phase Process\nPhase 1: Research Design & User Recruitment\n\nWhat I did: Structured a three-condition experiment (Nap, Meditation, Active Wakefulness) conducted over multiple days.\nWhy I did it: Enabled clear comparisons among cognitive states, minimizing confounding variables like anxiety through the multi-day design.\nWhat I did: Established precise participant screening criteria (e.g., must be habitual meditators/nappers).\nWhy I did it: Ensured genuine representation of targeted cognitive states, enhancing the validity and applicability of the results.\n\nPhase 2: Mixed-Methods Data Collection\n\nBehavioral Data: I chose word-pair and marble-maze tasks. These tasks distinctly measured factual recall (declarative) and motor skill acquisition (procedural), aligning with the study‚Äôs dual-memory focus.\n\n\n\n\n\n\n\n\nThe marble maze apparatus used to measure procedural motor skill learning.\n\n\n\nPhysiological Data: I collected multi-channel EEG recordings. This objective physiological data captured precise cognitive states, surpassing the reliability of self-report alone.\nSelf-Report Data: I administered validated scales (ESS, FMI). This added subjective insights into the participant experience, complementing the objective EEG data.\n\nPhase 3: Analysis & Synthesis\n\nProcessed and visually scored hours of multi-channel EEG data, epoch by epoch, to objectively classify sleep stages and identify ‚Äòmeditative states.‚Äô\nUtilized Bayesian statistical modeling in R, which is optimal for reliable interpretation, particularly with smaller, nuanced datasets.\nEmployed a G-Mean calculation for declarative memory analysis to handle class imbalance in the test data, ensuring unbiased accuracy of results.\n\n\n\n\nüí° Key Insight #1: For learning facts, quiet focus beats a nap.\n\nWhat I Found: Mindfulness meditators showed a significant advantage in memory retention over participants in an active-waking state (watching a video). Furthermore, their performance trended higher than those who took a short nap, suggesting that for factual learning, quiet wakefulness is a powerful and reliable tool for memory consolidation.\nThe ‚ÄúSo What?‚Äù: Quiet, focused wakefulness is optimal for factual learning, suggesting intentional meditation breaks could greatly enhance retention of new information.\nPotential Application: Companies like Duolingo, Coursera, or even corporate onboarding programs could integrate structured, guided meditation intervals into training modules to boost user learning and long-term retention of educational content.\n\n\n\n\n\n\n\n\nPerformance on the declarative memory task was highest in the Meditation (MED) group.\n\n\n\n\n\nüí° Key Insight #2: Deep naps can temporarily hurt physical skills.\n\nWhat I Found: Participants experiencing only light sleep improved their motor skills, while those entering deep Slow-Wave Sleep (SWS) experienced post-nap performance impairments, attributed to sleep inertia.\nThe ‚ÄúSo What?‚Äù: The depth of a nap critically influences post-rest performance on physical tasks. For users needing immediate peak performance, an unintended deep nap could be counterproductive.\nPotential Application: Smartwatch companies (like Apple or Google/Fitbit) developing smart alarm features could optimize wake-up times to avoid interrupting SWS. This feature would be critical for roles requiring immediate alertness and precision post-rest, such as shift workers, healthcare professionals, pilots, or drivers in logistics.\n\n\n\n\n\n\n\n\nPerformance on the maze task improved with more light sleep (pink line) but worsened with more deep sleep (blue line), highlighting the impact of sleep inertia.\n\n\n\n\n\nüöß Challenges & Learnings\n\nChallenge 1: Validating a Novel Task. The marble maze was a new method for assessing procedural memory.\n\nWhat I Learned: This taught me the importance of assessing the criterion validity of new research instruments. In a future iteration, I would correlate its results with a well-established motor skills task to build a stronger case for its reliability.\n\nChallenge 2: Unbalanced Demographics. The exploratory analysis revealed that gender might influence performance on different memory types, but the sample was not balanced for this comparison.\n\nWhat I Learned: This experience underscored the value of user segmentation. Going forward, I would proactively balance demographic cells in my recruiting plans, adopting a more iterative, UX-oriented approach to confidently analyze how different user groups might behave.\n\n\n\n\n\nüìö Publications & Impact\nThe insights from this research were not only compelling but also sparked a broader conversation in the scientific community. The work led directly to a peer-reviewed publication in a leading journal, demonstrating its scientific rigor and relevance:\n\nPeer-Reviewed Publication:\n\nDastgheib, M., Kulanayagam, A., & Dringenberg, H. C. (2022). Is the role of sleep in memory consolidation overrated? Neuroscience & Biobehavioral Reviews, 140, 104799. https://doi.org/10.1016/j.neubiorev.2022.104799\n\nOriginal Thesis & Presentation:\n\nRead the full Master‚Äôs Thesis (External Link)\nView the Presentation Slides (External Link)\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "publications/publication4/index.html",
    "href": "publications/publication4/index.html",
    "title": "Current Diagnostic Approaches to Patients with Hypernatremia at University Health Network Hospitals",
    "section": "",
    "text": "Background: Hypernatremia is a common electrolyte disorder where serum Na + Concentration is &gt;145 mM, and is frequently identified as an issue in patients admitted under general internal medicine 1,2 . The etiology can generally be classified as loss of free water or decreased intake, iatrogenic ingestion/infusion of hypertonic solution, or pseudohypernatremia 3 . It is a common practice to assume decreased intake of free water or extrarenal free water loss as the etiology, and to treat the hypernatremia with administration of hypotonic crystalloid solution without investigation of serum or urine osmolality, electrolytes, urea, or creatinine to delineate etiology 3,4 . In particular, the two often neglected diagnoses are diabetes insipidus and osmotic-induced diuresis. Etiology of hypernatremia is occasionally elusive and refractory to administration of crystalloid solution. However, laboratory investigations ordered by clinicians to properly determine underlying etiology of hypernatremia in these cases are not routine and may vary significantly. Objectives: We hypothesized that appropriate ordering of serum and urine studies by clinicians to determine the etiology of hypernatremia is related to the severity of hypernatremia. In addition, we aim to determine the etiology of hypernatremia that trigger clinician ordering of serum/urine studies. Methods: Patients admitted under general internal medicine at hospitals affiliated with the University Health Network (Toronto Western Hospital and Toronto General Hospital) between the dates of 2015 and 2019 with a serum sodium concentration of 150 mmol/L or greater were selected and assessed for completion of serum electrolytes, serum osmolality, urine electrolytes (Na, K, Cl), urine osmolality, urine creatinine, and urine urea. Discharge summaries were analysed to determine etiology and treatment of hypernatremia as well as treatments initiated. The research proposal was approved by Coordinated Approval Process for Clinical Research (CAPCR) at the University Health Network. Results: Based on our preliminary results, we were able to identify 606 cases of admitted general internal medicine patients with hypernatremia meeting our criteria. In our preliminary analysis of 47 cases, we were able to identify 18 cases (38.3%) with serum osmolality, 19 cases (40.4%) with urine osmolality, 23 cases (48.9%) with urine electrolytes, 1 case (2.1%) with urine urea, and 1 case (2.1%) with urine creatinine. There were 11 cases (23.4%) with all of serum osmolality, urine osmolality, and urine electrolytes. In general, the severity of hypernatremia correlated poorly with the number additional investigations ordered beyond serum electrolytes (ie. serum osmolality and urine studies; r 2 = 0.0204). Conclusion: In this study of patients with hypernatremia we found that a significant portion of admitted patients were not evaluated for urine studies, especially urea or creatinine. Unexpectedly, the severity of hypernatremia correlated poorly with the number of studies ordered to determine etiology, suggesting that the severity of hypernatremia may play a minor role in clinician ordering habits in hypernatremia. The current study signifies the importance of proper ordering and understanding of pathophysiology of hypernatremia and could contribute to filling the knowledge gap in appropriate ordering in hypernatremia, which may reduce the morbidity and mortality rate of hypernatremic patients."
  },
  {
    "objectID": "publications/publication4/index.html#abstract",
    "href": "publications/publication4/index.html#abstract",
    "title": "Current Diagnostic Approaches to Patients with Hypernatremia at University Health Network Hospitals",
    "section": "",
    "text": "Background: Hypernatremia is a common electrolyte disorder where serum Na + Concentration is &gt;145 mM, and is frequently identified as an issue in patients admitted under general internal medicine 1,2 . The etiology can generally be classified as loss of free water or decreased intake, iatrogenic ingestion/infusion of hypertonic solution, or pseudohypernatremia 3 . It is a common practice to assume decreased intake of free water or extrarenal free water loss as the etiology, and to treat the hypernatremia with administration of hypotonic crystalloid solution without investigation of serum or urine osmolality, electrolytes, urea, or creatinine to delineate etiology 3,4 . In particular, the two often neglected diagnoses are diabetes insipidus and osmotic-induced diuresis. Etiology of hypernatremia is occasionally elusive and refractory to administration of crystalloid solution. However, laboratory investigations ordered by clinicians to properly determine underlying etiology of hypernatremia in these cases are not routine and may vary significantly. Objectives: We hypothesized that appropriate ordering of serum and urine studies by clinicians to determine the etiology of hypernatremia is related to the severity of hypernatremia. In addition, we aim to determine the etiology of hypernatremia that trigger clinician ordering of serum/urine studies. Methods: Patients admitted under general internal medicine at hospitals affiliated with the University Health Network (Toronto Western Hospital and Toronto General Hospital) between the dates of 2015 and 2019 with a serum sodium concentration of 150 mmol/L or greater were selected and assessed for completion of serum electrolytes, serum osmolality, urine electrolytes (Na, K, Cl), urine osmolality, urine creatinine, and urine urea. Discharge summaries were analysed to determine etiology and treatment of hypernatremia as well as treatments initiated. The research proposal was approved by Coordinated Approval Process for Clinical Research (CAPCR) at the University Health Network. Results: Based on our preliminary results, we were able to identify 606 cases of admitted general internal medicine patients with hypernatremia meeting our criteria. In our preliminary analysis of 47 cases, we were able to identify 18 cases (38.3%) with serum osmolality, 19 cases (40.4%) with urine osmolality, 23 cases (48.9%) with urine electrolytes, 1 case (2.1%) with urine urea, and 1 case (2.1%) with urine creatinine. There were 11 cases (23.4%) with all of serum osmolality, urine osmolality, and urine electrolytes. In general, the severity of hypernatremia correlated poorly with the number additional investigations ordered beyond serum electrolytes (ie. serum osmolality and urine studies; r 2 = 0.0204). Conclusion: In this study of patients with hypernatremia we found that a significant portion of admitted patients were not evaluated for urine studies, especially urea or creatinine. Unexpectedly, the severity of hypernatremia correlated poorly with the number of studies ordered to determine etiology, suggesting that the severity of hypernatremia may play a minor role in clinician ordering habits in hypernatremia. The current study signifies the importance of proper ordering and understanding of pathophysiology of hypernatremia and could contribute to filling the knowledge gap in appropriate ordering in hypernatremia, which may reduce the morbidity and mortality rate of hypernatremic patients."
  },
  {
    "objectID": "publications/publication4/index.html#details",
    "href": "publications/publication4/index.html#details",
    "title": "Current Diagnostic Approaches to Patients with Hypernatremia at University Health Network Hospitals",
    "section": "Details",
    "text": "Details\n\nJournal: Canadian Journal of Anesthesia/Journal canadien d‚Äôanesth√©sie\nVolume: 67\nIssue: Supplement 1\nPages: 40-41\nPublisher: Springer Nature\nDate: 2020"
  },
  {
    "objectID": "publications/publication4/index.html#keywords",
    "href": "publications/publication4/index.html#keywords",
    "title": "Current Diagnostic Approaches to Patients with Hypernatremia at University Health Network Hospitals",
    "section": "Keywords",
    "text": "Keywords\n\nHypernatremia\nDiagnostic Approaches\nUniversity Health Network Hospitals"
  },
  {
    "objectID": "publications/publication4/index.html#citation",
    "href": "publications/publication4/index.html#citation",
    "title": "Current Diagnostic Approaches to Patients with Hypernatremia at University Health Network Hospitals",
    "section": "Citation",
    "text": "Citation\nSarwar, S., Shafiee, M. A., Dastgheib, M., Hajighadimi, S., Ghafarian, H., & Rokni, H. (2020). Current Diagnostic Approaches to Patients with Hypernatremia at University Health Network Hospitals. Canadian Journal of Anesthesia/Journal canadien d‚Äôanesth√©sie, 67(Supplement 1), 40-41. https://doi.org/10.1007/s12630-019-01552-z"
  },
  {
    "objectID": "publications/publication4/index.html#full-text",
    "href": "publications/publication4/index.html#full-text",
    "title": "Current Diagnostic Approaches to Patients with Hypernatremia at University Health Network Hospitals",
    "section": "Full Text",
    "text": "Full Text\nView Full Text"
  },
  {
    "objectID": "publications/publication5/index.html",
    "href": "publications/publication5/index.html",
    "title": "The Differential Effect of Physical Effort within Perceptual and Visual Memory Domains: Insights from Psychometric Function Analysis",
    "section": "",
    "text": "This poster presents the differential effect of physical effort within perceptual and visual memory domains, using insights from psychometric function analysis."
  },
  {
    "objectID": "publications/publication5/index.html#abstract",
    "href": "publications/publication5/index.html#abstract",
    "title": "The Differential Effect of Physical Effort within Perceptual and Visual Memory Domains: Insights from Psychometric Function Analysis",
    "section": "",
    "text": "This poster presents the differential effect of physical effort within perceptual and visual memory domains, using insights from psychometric function analysis."
  },
  {
    "objectID": "publications/publication5/index.html#details",
    "href": "publications/publication5/index.html#details",
    "title": "The Differential Effect of Physical Effort within Perceptual and Visual Memory Domains: Insights from Psychometric Function Analysis",
    "section": "Details",
    "text": "Details\n\nConference: Psychonomic Society Annual Meeting\nDate: 2024\nAuthors: Dastgheib, M., Bennett, I., Seitz, A."
  },
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "Publications & Presentations",
    "section": "",
    "text": "This section includes articles that have undergone a formal peer-review process and have been published in academic journals.\n\n\n\n\n\n\nNeuroscience & Biobehavioral Reviews, Volume 140.\n\n\n\n\n\nAugust 2022\n\n\nDastgheib, M., Kulanayagam, A., & Dringenberg, H. C.\n\n\n\n\n\nNo matching items\n\n\n\n\nCuriosity Daily Podcast (Discovery) featured my review article\nIs the role of sleep in memory consolidation overrated? (Neuroscience & Biobehavioral Reviews, 2022).\nüéß Listen here\nThe Boston Globe: Five facts about sleep everyone should know\nThe Harvard Gazette: Researchers one step closer to understanding daydreams\n\n\n\n\n\nDastgheib, M., Sun, A., Yaghoubi, K., Chen, X., Peters, M., Zhang, W., Bennett, I., Seitz, A. (In Prep). The Effect of Physical Effort on Perception and Visual Memory: A Pupillometric Analysis.\nDastgheib, M., Sun, A., Maniscalco, B., Peters, M., Seitz, A. (In Prep). Analysis of metacognitive efficiency in younger and older adults in auditory and visual perceptual task."
  },
  {
    "objectID": "publications/index.html#peer-reviewed-articles",
    "href": "publications/index.html#peer-reviewed-articles",
    "title": "Publications & Presentations",
    "section": "",
    "text": "This section includes articles that have undergone a formal peer-review process and have been published in academic journals.\n\n\n\n\n\n\nNeuroscience & Biobehavioral Reviews, Volume 140.\n\n\n\n\n\nAugust 2022\n\n\nDastgheib, M., Kulanayagam, A., & Dringenberg, H. C.\n\n\n\n\n\nNo matching items\n\n\n\n\nCuriosity Daily Podcast (Discovery) featured my review article\nIs the role of sleep in memory consolidation overrated? (Neuroscience & Biobehavioral Reviews, 2022).\nüéß Listen here\nThe Boston Globe: Five facts about sleep everyone should know\nThe Harvard Gazette: Researchers one step closer to understanding daydreams\n\n\n\n\n\nDastgheib, M., Sun, A., Yaghoubi, K., Chen, X., Peters, M., Zhang, W., Bennett, I., Seitz, A. (In Prep). The Effect of Physical Effort on Perception and Visual Memory: A Pupillometric Analysis.\nDastgheib, M., Sun, A., Maniscalco, B., Peters, M., Seitz, A. (In Prep). Analysis of metacognitive efficiency in younger and older adults in auditory and visual perceptual task."
  },
  {
    "objectID": "publications/index.html#dissertations-theses",
    "href": "publications/index.html#dissertations-theses",
    "title": "Publications & Presentations",
    "section": "üéì Dissertations & Theses",
    "text": "üéì Dissertations & Theses\nMajor independent research projects completed as part of my graduate training.\n\nDoctoral Dissertation (In Progress): The Influence of Arousal and Cognitive Reserve on Dual-Task Interference in Aging. (University of California, Riverside)\nMaster‚Äôs Thesis: The Effects of Self-Guided Meditation and Napping on Memory Consolidation in Humans. (Queen‚Äôs University) ‚Äî View on OSF Preprints"
  },
  {
    "objectID": "publications/index.html#conference-presentations-published-abstracts",
    "href": "publications/index.html#conference-presentations-published-abstracts",
    "title": "Publications & Presentations",
    "section": "üé§ Conference Presentations & Published Abstracts",
    "text": "üé§ Conference Presentations & Published Abstracts\nA selection of posters and talks presented at scientific conferences, with my name in bold.\n\nInternational Presentations\n\nSun, A., Dastgheib, M., Maniscalco, B., Peters, M., Zhang, W., Seitz, A. (2025, June). Selective Modulation of Auditory Perception and Metacognition by Hand Grip-Based Arousal in Older Adults. Talk at the Metacognition, Aging and Perception Symposium (MAPS), Rovereto, Italy.\nGhaffari, A., Langley, J., Dastgheib, M., Chen, X., Bennett, I., Hu, X. (2025, May). Functional MRI Connectome Fingerprinting in Older Adults. Talk at the IEEE International Symposium on Biomedical Imaging (ISBI), Houston, TX.\nDastgheib, M., Bennett, I., Seitz, A. (2024, November). The Differential Effect of Physical Effort within Perceptual and Visual Memory Domains: Insights from Psychometric Function Analysis. Poster presented at the 65th Annual Meeting of the Psychonomic Society, New York City, NY.\nDastgheib, M., Yaghoubi, K., Kobaissi, H., Alba, J., Bennett, I., Seitz, A. (2023, August). The Effect of Physical Effort on Perception and Visual Memory. Poster presented at the International Conference on Learning and Memory, Huntington Beach, CA.\nDastgheib, M., Legro L., Stewart M., Dringenberg H. (2019, June). The Effects of Self-guided Meditation and Napping on Non-Declarative and Declarative Memory Consolidation. Poster presented at the Canadian Society for Brain, Behaviour, & Cognitive Sciences (CSBBCS) meeting, Waterloo, ON.\n\n\n\nPublished Abstracts\n\nSarwar, S., Shafiee, M., Dastgheib, M., Hajighadimi, S., Ghafarian, H., Rokni, H. (2020). Current Diagnostic Approaches to Patients with Hypernatremia at University Health Network Hospitals. Canadian Journal of Anesthesia, 67(S1), 1-162. DOI Link\n\n\n\nIntramural Presentations\n\nSarwar, S., Shafiee, M., Dastgheib, M., et al.¬†(2019). Current Diagnostic Approaches to Patients with Hypernatremia at University Health Network Hospitals. Critical Care Canada Forum (CCCF), Toronto, ON.\nDastgheib, M., Legro L., Stewart M., Dringenberg H. (2018). The Effects of Self-guided Meditation and Napping on Non-Declarative and Declarative Memory Consolidation. Southern Ontario Neuroscience Association (SONA) conference, Guelph, ON.\nDastgheib, M. (2017). Are Older Adults‚Äô Attitudes about Aging Influenced by a Psychoeducational Program? Psychology Undergraduate Thesis Poster Day, York University, Toronto, ON."
  },
  {
    "objectID": "publications/publication8/index.html",
    "href": "publications/publication8/index.html",
    "title": "The Effects of Self-guided Meditation and Napping on Non-Declarative and Declarative Memory Consolidation",
    "section": "",
    "text": "This poster presents the effects of self-guided meditation and napping on both non-declarative and declarative memory consolidation. The study examines the impact of these interventions on memory performance and discusses the underlying mechanisms."
  },
  {
    "objectID": "publications/publication8/index.html#abstract",
    "href": "publications/publication8/index.html#abstract",
    "title": "The Effects of Self-guided Meditation and Napping on Non-Declarative and Declarative Memory Consolidation",
    "section": "",
    "text": "This poster presents the effects of self-guided meditation and napping on both non-declarative and declarative memory consolidation. The study examines the impact of these interventions on memory performance and discusses the underlying mechanisms."
  },
  {
    "objectID": "publications/publication8/index.html#details",
    "href": "publications/publication8/index.html#details",
    "title": "The Effects of Self-guided Meditation and Napping on Non-Declarative and Declarative Memory Consolidation",
    "section": "Details",
    "text": "Details\n\nConference: Southern Ontario Neuroscience Association (SONA) conference\nLocation: Guelph, ON\nDate: 2018\nAuthors: Mohammad Dastgheib, Legro L., Stewart M., Hans C. Dringenberg"
  },
  {
    "objectID": "publications/publication8/index.html#keywords",
    "href": "publications/publication8/index.html#keywords",
    "title": "The Effects of Self-guided Meditation and Napping on Non-Declarative and Declarative Memory Consolidation",
    "section": "Keywords",
    "text": "Keywords\n\nMemory Consolidation\nSelf-Guided Meditation\nNapping\nCognitive Neuroscience"
  },
  {
    "objectID": "publications/publication8/index.html#citation",
    "href": "publications/publication8/index.html#citation",
    "title": "The Effects of Self-guided Meditation and Napping on Non-Declarative and Declarative Memory Consolidation",
    "section": "Citation",
    "text": "Citation\nDastgheib, M., Legro L., Stewart M., & Dringenberg, H. C. (2018). The Effects of Self-guided Meditation and Napping on Non-Declarative and Declarative Memory Consolidation. Presented at the Southern Ontario Neuroscience Association (SONA) conference, Guelph, ON."
  },
  {
    "objectID": "publications/publication1/index.html",
    "href": "publications/publication1/index.html",
    "title": "The Effect of Physical Effort on Perception and Visual Memory: A Pupillometric Analysis",
    "section": "",
    "text": "This study investigates the effect of physical effort on perception and visual memory using pupillometry. We designed and implemented psychophysical experiments to analyze the impact of physical exertion on visual perception and memory consolidation."
  },
  {
    "objectID": "publications/publication1/index.html#abstract",
    "href": "publications/publication1/index.html#abstract",
    "title": "The Effect of Physical Effort on Perception and Visual Memory: A Pupillometric Analysis",
    "section": "",
    "text": "This study investigates the effect of physical effort on perception and visual memory using pupillometry. We designed and implemented psychophysical experiments to analyze the impact of physical exertion on visual perception and memory consolidation."
  },
  {
    "objectID": "publications/publication1/index.html#details",
    "href": "publications/publication1/index.html#details",
    "title": "The Effect of Physical Effort on Perception and Visual Memory: A Pupillometric Analysis",
    "section": "Details",
    "text": "Details\n\nJournal: Manuscript in preparation\nAuthors: Mohammad Dastgheib, et al.\nDate: TBD"
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research Interests",
    "section": "",
    "text": "My doctoral research investigates the intricate relationship between physiological arousal, cognitive effort, and the integrity of the human brain‚Äôs neuromodulatory systems. I am fundamentally interested in understanding why cognitive performance, particularly in aging, becomes vulnerable under demanding real-world conditions.\nMy work aims to move beyond simple behavioral metrics by integrating psychophysics, pupillometry, and computational modeling to deconstruct the subcomponents of decision-making. By precisely measuring the impact of physical and cognitive load, I seek to build predictive models of performance that can inform the design of safer, more adaptive, and more inclusive technologies for a range of user populations."
  },
  {
    "objectID": "research/index.html#research-statement",
    "href": "research/index.html#research-statement",
    "title": "Research Interests",
    "section": "",
    "text": "My doctoral research investigates the intricate relationship between physiological arousal, cognitive effort, and the integrity of the human brain‚Äôs neuromodulatory systems. I am fundamentally interested in understanding why cognitive performance, particularly in aging, becomes vulnerable under demanding real-world conditions.\nMy work aims to move beyond simple behavioral metrics by integrating psychophysics, pupillometry, and computational modeling to deconstruct the subcomponents of decision-making. By precisely measuring the impact of physical and cognitive load, I seek to build predictive models of performance that can inform the design of safer, more adaptive, and more inclusive technologies for a range of user populations."
  },
  {
    "objectID": "research/index.html#core-research-areas",
    "href": "research/index.html#core-research-areas",
    "title": "Research Interests",
    "section": "Core Research Areas",
    "text": "Core Research Areas\nMy research program is built on five interconnected pillars:\n\nAging & Cognitive Neuroscience: Characterizing how age-related changes in the Locus Coeruleus (LC) and its associated neural circuits impact cognitive functions, with a focus on identifying potential biomarkers for neurodegenerative disorders.\nDual-Task Interference & Performance: Quantifying how concurrent physical and cognitive stressors interact to impair performance across multiple domains, including perception, memory, and metacognition.\nApplied Human Factors: Translating cognitive science insights to real-world high-stakes environments (aerospace, healthcare, manufacturing) to enhance safety and performance through data-driven design.\nAdaptive Interfaces & Extended Reality (XR): Designing and evaluating adaptive modality systems that dynamically adjust input methods (e.g., gaze vs.¬†hand-pointing) based on cognitive load and performance metrics, with applications to XR environments and human-computer interaction.\nPersonalized Cognitive Modeling: Moving beyond group averages to model how individual differences in factors like Cognitive Reserve predict a person‚Äôs unique resilience to cognitive overload, including computational approaches that link physiological measures (pupillometry) with decision-making processes."
  },
  {
    "objectID": "research/index.html#methodological-expertise",
    "href": "research/index.html#methodological-expertise",
    "title": "Research Interests",
    "section": "üõ†Ô∏è Methodological Expertise",
    "text": "üõ†Ô∏è Methodological Expertise\nTo address these questions, I specialize in a multi-modal approach to data collection and analysis:\n\nPsychophysics: Designing and implementing precise behavioral experiments to measure perceptual and memory thresholds (PsychToolbox).\nPupillometry: Using pupil dilation as a real-time, non-invasive biomarker of cognitive load and physiological arousal (MATLAB, R, Python). Developing computational models that integrate pupillometry with decision-making frameworks (e.g., Drift-Diffusion Model) to understand the interplay between physiological responses and cognitive processes.\nMachine Learning: Developing predictive models for cognitive state classification using ensemble methods (XGBoost), feature engineering, and cross-validation techniques.\nComputational Modeling: Applying models like the Drift-Diffusion Model (DDM) to deconstruct decision-making processes, with ongoing work on linking DDM parameters to pupillometric dynamics to provide mechanistic insights into cognitive effort and arousal.\nExtended Reality (XR) Development: Building research platforms for adaptive modality systems, implementing Fitts‚Äôs Law paradigms with dual input methods (gaze and hand-pointing), and developing real-time adaptive UI interventions based on performance metrics and cognitive load estimates.\nAdvanced Statistical Analysis: Employing linear mixed-effects models and Bayesian methods for complex, repeated-measures data (R). Implementing pre-registered experimental designs with rigorous exclusion criteria and equivalence testing.\nNeuroimaging: Analyzing Diffusion MRI data to investigate white matter integrity and its relationship to behavior (FSL, QSIPrep).\nReal-Time Analytics: Building interactive dashboards and monitoring systems for applied research contexts (R Shiny, web technologies). Developing web-based experimental platforms with precise timing control, comprehensive data logging, and real-time performance monitoring."
  },
  {
    "objectID": "research/index.html#research-in-action",
    "href": "research/index.html#research-in-action",
    "title": "Research Interests",
    "section": "üöÄ Research in Action",
    "text": "üöÄ Research in Action\nSee concrete applications of these research approaches in my Portfolio, featuring case studies that demonstrate the translation of cognitive science principles to real-world challenges in aerospace, healthcare, and education."
  },
  {
    "objectID": "research/index.html#current-research-focus",
    "href": "research/index.html#current-research-focus",
    "title": "Research Interests",
    "section": "üéØ Current Research Focus",
    "text": "üéØ Current Research Focus\nPhD Dissertation (2025): ‚ÄúA Psychophysiological Approach to Modeling Dual-Task Interference: Pupillometry, Cognitive Reserve, and Personalized Performance Prediction‚Äù\nThis research aims to develop a comprehensive framework for predicting when and why individuals experience cognitive overload in dual-task scenarios, with applications to aging, technology design, and occupational safety. Building on my dissertation prospectus, the program integrates:\n\nPre-registered psychophysics and pupillometry experiments to characterize how neuromodulatory state and Cognitive Reserve shape dual-task interference across the adult lifespan.\nApplied human factors case studies (e.g., surgical performance monitoring and adaptive XR interfaces) that translate these mechanisms into real-world, safety-critical settings.\nComputational modeling and machine learning, including Drift-Diffusion Models linked to pupil dynamics and calibrated predictive models of cognitive state, to move toward individualized performance prediction and adaptive assistance policies.\n\nTogether, these strands are designed to bridge basic cognitive neuroscience, physiological measurement, and deployable human-centered technologies."
  },
  {
    "objectID": "publications/publication6/index.html",
    "href": "publications/publication6/index.html",
    "title": "The Effect of Physical Effort on Perception and Visual Memory",
    "section": "",
    "text": "This poster investigates the effect of physical effort on perception and visual memory using pupillometry."
  },
  {
    "objectID": "publications/publication6/index.html#abstract",
    "href": "publications/publication6/index.html#abstract",
    "title": "The Effect of Physical Effort on Perception and Visual Memory",
    "section": "",
    "text": "This poster investigates the effect of physical effort on perception and visual memory using pupillometry."
  },
  {
    "objectID": "publications/publication6/index.html#details",
    "href": "publications/publication6/index.html#details",
    "title": "The Effect of Physical Effort on Perception and Visual Memory",
    "section": "Details",
    "text": "Details\n\nConference: International Conference on Learning and Memory\nDate: 2023\nAuthors: Dastgheib, M., Yaghoubi, K., Kobaissi, H., Alba, J., Bennett, I., Seitz, A."
  },
  {
    "objectID": "publications/publication7/index.html",
    "href": "publications/publication7/index.html",
    "title": "The Effects of Self-guided Meditation and Napping on Non-Declarative and Declarative Memory Consolidation",
    "section": "",
    "text": "This conference presentation explores the effects of self-guided meditation and napping on both non-declarative and declarative memory consolidation. The study examines the impact of these interventions on memory performance and discusses the underlying mechanisms."
  },
  {
    "objectID": "publications/publication7/index.html#abstract",
    "href": "publications/publication7/index.html#abstract",
    "title": "The Effects of Self-guided Meditation and Napping on Non-Declarative and Declarative Memory Consolidation",
    "section": "",
    "text": "This conference presentation explores the effects of self-guided meditation and napping on both non-declarative and declarative memory consolidation. The study examines the impact of these interventions on memory performance and discusses the underlying mechanisms."
  },
  {
    "objectID": "publications/publication7/index.html#details",
    "href": "publications/publication7/index.html#details",
    "title": "The Effects of Self-guided Meditation and Napping on Non-Declarative and Declarative Memory Consolidation",
    "section": "Details",
    "text": "Details\n\nConference: Canadian Society for Brain, Behaviour, & Cognitive Sciences meeting\nLocation: Waterloo, ON\nDate: 2019\nAuthors: Mohammad Dastgheib, Legro L., Stewart M., Hans C. Dringenberg"
  },
  {
    "objectID": "publications/publication7/index.html#keywords",
    "href": "publications/publication7/index.html#keywords",
    "title": "The Effects of Self-guided Meditation and Napping on Non-Declarative and Declarative Memory Consolidation",
    "section": "Keywords",
    "text": "Keywords\n\nMemory Consolidation\nSelf-Guided Meditation\nNapping\nCognitive Neuroscience"
  },
  {
    "objectID": "publications/publication7/index.html#citation",
    "href": "publications/publication7/index.html#citation",
    "title": "The Effects of Self-guided Meditation and Napping on Non-Declarative and Declarative Memory Consolidation",
    "section": "Citation",
    "text": "Citation\nDastgheib, M., Legro L., Stewart M., & Dringenberg, H. C. (2019). The Effects of Self-guided Meditation and Napping on Non-Declarative and Declarative Memory Consolidation. Presented at the Canadian Society for Brain, Behaviour, & Cognitive Sciences meeting, Waterloo, ON."
  },
  {
    "objectID": "publications/peer-reviewed/dastgheib-2022-neurobio-reviews.html",
    "href": "publications/peer-reviewed/dastgheib-2022-neurobio-reviews.html",
    "title": "Is the role of sleep in memory consolidation overrated?",
    "section": "",
    "text": "Abstract\n\n\n\n\n\nSubstantial empirical evidence suggests that sleep benefits the consolidation and reorganization of learned information. Consequently, the concept of ‚Äúsleep-dependent memory consolidation‚Äù is now widely accepted by the scientific community, in addition to influencing public perceptions regarding the functions of sleep. There are, however, numerous studies that have presented findings inconsistent with the sleep-memory hypothesis. Here, we challenge the notion of ‚Äúsleep-dependency‚Äù by summarizing evidence for effective memory consolidation independent of sleep. Plasticity mechanisms thought to mediate or facilitate consolidation during sleep (e.g., neuronal replay, reactivation, slow oscillations, neurochemical milieu) also operate during non-sleep states, particularly quiet wakefulness, thus allowing for the stabilization of new memories. We propose that it is not sleep per se, but the engagement of plasticity mechanisms, active during both sleep and (at least some) waking states, that constitutes the critical factor determining memory formation. Thus, rather than playing a ‚Äúcritical‚Äù role, sleep falls along a continuum of behavioral states that vary in their effectiveness to support memory consolidation at the neural and behavioral level.\n\n\n\nView Publication (DOI) Download PDF\n\n\n\n\n\n\nMedia Coverage\n\n\n\nCuriosity Daily Podcast (Discovery) Episode: Daydream Brain, Power of a Laugh, Caffeine & Soccer Original release: Jan 25, 2024 ¬∑ Re-release: Dec 19, 2024\n\n\nListen on Acast\n\nThe Boston Globe: Five facts about sleep everyone should know\nThe Harvard Gazette: Researchers one step closer to understanding daydreams\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "publications/publication3/index.html",
    "href": "publications/publication3/index.html",
    "title": "The Effects of Self-Guided Meditation and Napping on Memory Consolidation in Humans",
    "section": "",
    "text": "This Master‚Äôs thesis investigates the effects of self-guided meditation and napping on memory consolidation in humans. The study examines whether these interventions can enhance memory performance and explores the underlying mechanisms."
  },
  {
    "objectID": "publications/publication3/index.html#abstract",
    "href": "publications/publication3/index.html#abstract",
    "title": "The Effects of Self-Guided Meditation and Napping on Memory Consolidation in Humans",
    "section": "",
    "text": "This Master‚Äôs thesis investigates the effects of self-guided meditation and napping on memory consolidation in humans. The study examines whether these interventions can enhance memory performance and explores the underlying mechanisms."
  },
  {
    "objectID": "publications/publication3/index.html#details",
    "href": "publications/publication3/index.html#details",
    "title": "The Effects of Self-Guided Meditation and Napping on Memory Consolidation in Humans",
    "section": "Details",
    "text": "Details\n\nUniversity: Queen‚Äôs University\nDegree: M.Sc. in Psychology\nDate: 2020\nAdvisor: Hans C. Dringenberg"
  },
  {
    "objectID": "publications/publication3/index.html#keywords",
    "href": "publications/publication3/index.html#keywords",
    "title": "The Effects of Self-Guided Meditation and Napping on Memory Consolidation in Humans",
    "section": "Keywords",
    "text": "Keywords\n\nMemory Consolidation\nSelf-Guided Meditation\nNapping\nCognitive Neuroscience"
  },
  {
    "objectID": "publications/publication3/index.html#citation",
    "href": "publications/publication3/index.html#citation",
    "title": "The Effects of Self-Guided Meditation and Napping on Memory Consolidation in Humans",
    "section": "Citation",
    "text": "Citation\nDastgheib, M. (2020). The Effects of Self-Guided Meditation and Napping on Memory Consolidation in Humans. Master‚Äôs thesis, Queen‚Äôs University."
  },
  {
    "objectID": "publications/publication3/index.html#full-text",
    "href": "publications/publication3/index.html#full-text",
    "title": "The Effects of Self-Guided Meditation and Napping on Memory Consolidation in Humans",
    "section": "Full Text",
    "text": "Full Text\nView Full Text"
  },
  {
    "objectID": "projects/surgeon-performance-predict2.html#why-i-built-this",
    "href": "projects/surgeon-performance-predict2.html#why-i-built-this",
    "title": "Surgeon Cognitive Dashboard ‚Äî Case Study",
    "section": "Why I built this",
    "text": "Why I built this\n\n\n\n\n\n\n\n\n\n\n\nSurgical Safety Technologies (SST)\n(Research Assistant / AI Annotator).\n\n\n\n  \n    Assisted on instance segmentation\n    \n      \n    \n    for tool detection/tracking\n  \n\n  \n    Computed inter-rater reliability (Œ∫/ICC)\n    \n      \n    \n    for analyst labels\n  \n\n  \n    Reviewed ML-for-safety literature\n    \n      \n    \n    to support analyst operations\n  \n\n\n\n  ‚Üí Lesson: labels drift\n  \n    \n  ,\n  interfaces & alarm hygiene decide adoption\n  \n    \n  .\n\n\n\n\n\nUC Riverside\n(PhD project and dissertation).\n\n\n\n  \n    Test concurrent physical (5% vs 40% MVC\n    \n      \n    )\n    √ó cognitive effort with pupillometry\n    \n      \n    \n  \n\n  \n    Domains: working/long-term memory + auditory/visual discrimination\n    \n      \n    \n  \n\n  \n    Theories: Resource Competition\n    \n      \n    \n    + Neural Gain (adaptive gain)\n    \n      \n    \n  \n\n\n\n  ‚Üí Mechanism: pupil-indexed LC‚ÄìNE\n  \n    \n  \n  links arousal to performance.\n\n\n\n\nWhy this dashboard: combine deployable UX from SST with mechanistic LC‚ÄìNE insight to deliver a\n  training-first, no extra wearables cognitive monitor for robotic trainees."
  },
  {
    "objectID": "projects/surgeon-performance-predict2.html#executive-summary",
    "href": "projects/surgeon-performance-predict2.html#executive-summary",
    "title": "Surgeon Cognitive Dashboard ‚Äî Case Study",
    "section": "Executive Summary",
    "text": "Executive Summary\nSurgery is a cognitive sport. When arousal is balanced, performance peaks; when it‚Äôs too low or too high, errors creep in. The OR is tightly constrained‚Äîso we avoid new body-worn hardware and lengthy calibration, and instead fuse existing robot telemetry with unobtrusive biosignals to deliver real-time coaching.\nI built two tightly coupled tools:\n\nTraining Lab: makes load/fatigue felt and lets instructors choose a threshold policy to match their pedagogy.\nProduction Dashboard: runs those policies in real time using pupil + grip/tremor + HRV, tuned to prevent alarm fatigue and respect sterile-field constraints.\n\nAccuracy is necessary, not sufficient. We optimize for operational outcomes‚Äîfewer high-load minutes, faster recovery, quicker proficiency‚Äîalongside standard model metrics.\n\n\n\n\n\n\nNote\n\n\n\nDeployment KPIs: Alert burden ‚â§ 0.6/min, High-Load min/hr ‚Üì, Time-to-Recovery sec ‚Üì, Acknowledgement rate ‚Üë.\n\n\n\n\n\n\n  \n    \n      \n        \n        Surgical Cognitive Dashboard\n      \n      \n    \n    No body-worn hardware, real-time neuro-ergonomics for robotic surgery.\n    \n      \n        \n        \n      \n      \n        \n          Open repo\n        \n      \n    \n  \n\n  \n    \n      \n        \n        Surgical Training Lab\n      \n      \n    \n    Interactive policy sandbox: Inverted-U ¬∑ SDT ¬∑ Fatigue-adaptive.\n    \n      \n        \n        \n      \n      \n        \n          Open repo"
  },
  {
    "objectID": "projects/surgeon-performance-predict2.html#objectives-what-this-actually-delivers",
    "href": "projects/surgeon-performance-predict2.html#objectives-what-this-actually-delivers",
    "title": "Surgeon Cognitive Dashboard ‚Äî Case Study",
    "section": "Objectives ‚Äî what this actually delivers",
    "text": "Objectives ‚Äî what this actually delivers\n\nClinical ergonomics, not gadgetry. Non-intrusive biosignals (pupil, HRV, grip/tremor) + robot telemetry ‚Üí actionable state estimates (Normal / High-Load / Lapse).\nTraining outcomes, not scoreboards. Reduce high-load minutes per hour, shorten time-to-recovery after microbreaks, and accelerate time-to-proficiency.\nPedagogy built-in. Three threshold policies map to real teaching strategies: Adaptive Gain (arousal sweet-spot), Dual-Criterion (SDT) (false-alarm control + hysteresis), Time-on-Task (fatigue & microbreaks).\nDeployable now. Sterile-field-friendly, &lt;60-second setup; sensible defaults, guardrails against alarm spam, and readable explanations."
  },
  {
    "objectID": "projects/surgeon-performance-predict2.html#who-benefits-and-why",
    "href": "projects/surgeon-performance-predict2.html#who-benefits-and-why",
    "title": "Surgeon Cognitive Dashboard ‚Äî Case Study",
    "section": "Who benefits ‚Äî and why",
    "text": "Who benefits ‚Äî and why\n\nResidents. See when trainees drift into low arousal or overload; get just-enough nudge (microbreaks, pacing, framing) without flooding them.\nInstructors. A common language for when to step in: high-load confirmed by TEPR‚Üë + HRV‚Üì, lapse suggested by low TEPR + blink anomalies.\nProgram directors / ops. Track high-load min/hr, recovery latency, and alarm burden across sessions to prove training impact and tune curricula."
  },
  {
    "objectID": "projects/surgeon-performance-predict2.html#personalized-coaching-how-it-adapts-to-the-trainee",
    "href": "projects/surgeon-performance-predict2.html#personalized-coaching-how-it-adapts-to-the-trainee",
    "title": "Surgeon Cognitive Dashboard ‚Äî Case Study",
    "section": "Personalized coaching ‚Äî how it adapts to the trainee",
    "text": "Personalized coaching ‚Äî how it adapts to the trainee\nIdea. Each trainee has a different ‚Äúinverted-U‚Äù width and bias. We infer a coaching profile from early sessions:\n\nWide band: tolerates more challenge before overload ‚Üí allow denser feedback; push complexity sooner.\nNarrow band: tips into overload quickly ‚Üí favor microbreaks, chunk tasks, reduce concurrent demands.\n\nHeuristics (evidence-informed, lightweight):\n\nLikely overload (right limb): z(TEPR) ‚â• +0.8 AND RMSSD ‚Üì ‚â• 25‚Äì35% over 60‚Äì120 s ‚Üí suggest microbreak or slow tool motions for 60‚Äì120 s.\nLikely lapse (left side): z(TEPR) ‚â§ ‚àí0.5 OR blink bursts + stable HRV ‚Üí prompt re-centering (brief cueing, checklist, or instructor query).\nStable but trending: slope(High-Load prob, 90 s) &gt; 0 with rising grip CV ‚Üí anticipatory nudge (‚Äúprepare break after this step‚Äù).\n\n\nNot a diagnosis. This is training feedback, not medical inference. Requires individual calibration and instructor judgment.\n\nIf we want to surface the coaching logic UI-side, drop this explanatory microcopy under the Live Monitor:\nCoaching logic (transparent): Alerts fire on evidence + physiology with hysteresis to prevent chatter. HL requires TEPR‚Üë or HRV‚Üì; Lapse prefers low TEPR + blink anomalies. Policies then shape sensitivity (SDT), target the sweet-spot (Adaptive Gain), or relax with time (Fatigue)."
  },
  {
    "objectID": "projects/surgeon-performance-predict2.html#threshold-policies-how-they-work",
    "href": "projects/surgeon-performance-predict2.html#threshold-policies-how-they-work",
    "title": "Surgeon Cognitive Dashboard ‚Äî Case Study",
    "section": "Threshold Policies ‚Äî how they work",
    "text": "Threshold Policies ‚Äî how they work\nOne problem, three lenses. Each policy below answers: what changes, when to use it, and how it maps to the production dashboard defaults.\n\nAdaptive Gain (Inverted-U) Dual-Criterion (SDT) Time-on-Task Policy (Fatigue-Adaptive) \n\n\n\n\n\n\n\n\n\n\n\n\nX-axis detail: Normalized arousal \n\n  \n\n= fused TEPR + HRV index ‚àà [0,1].\n\n\nMaps to Dashboard. We fuse TEPR (‚Üë) and HRV (‚Üì) into a normalized arousal index ‚àà [0,1]. Alerts fire when the index leaves the optimal band [lo, hi].\n\nWider band ‚Üí fewer alerts, gentler coaching.\nNarrower band ‚Üí tighter coaching, higher nuisance risk.\nWe add hysteresis (small margins) to prevent alert ‚Äúchatter‚Äù at band edges.\n\nNotes for accuracy.\n\nThe inverted-U is task- and person-dependent: expertise, stakes, and fatigue shift the peak (band_center) and width (band_width). That‚Äôs why we calibrate per trainee.\n‚ÄúAdaptive gain‚Äù is the mechanism (LC-NE modulating neural gain) that can yield this non-monotonic performance curve.\n\nReferences. Yerkes‚ÄìDodson (1908); Aston-Jones & Cohen (2005, adaptive gain).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX-axis: a z-scored, signed evidence index from biosignals (e.g., TEPR‚Üë, RMSSD‚Üì).\nHigher ‚Üí High-Load; lower ‚Üí Lapse.\n\n\nWhat this shows. A three-state SDT layout (Lapse / Normal / High-Load) with two decision criteria and hysteresis (separate enter/exit thresholds).\n\ncriterion_tightness narrows or widens the Normal window by moving both criteria toward or away from 0.\ncoupling controls symmetry: values &lt; 1 move the Lapse boundary less than the High-Load boundary; values &gt; 1 move it more.\n\nWhy ‚ÄúDual-Criterion,‚Äù not ‚ÄúSensitivity.‚Äù In SDT, sensitivity is d‚Ä≤ (distribution separation). This policy adjusts decision criteria (bias), not d‚Ä≤.\n\nHow the two figures relate: The first figure defines the boundaries (enter/exit on each side). The second applies the same boundaries‚Äînudged slightly if needed so at least one crossing is visible‚Äîto a noisy signal, showing how hysteresis prevents flip-flops near a boundary.\n\n\n\n\n\n\n\n\n\n\nHysteresis. Enter/exit thresholds (and/or consecutive-sample confirmation) require persistent evidence to change state‚Äîreducing nuisance alerts.\nMaps to Dashboard. The control sets the HL and Lapse thresholds together. Alerts still require evidence + physiology (e.g., HL requires TEPR‚Üë or HRV‚Üì; Lapse prefers low TEPR + blink anomalies).\nReferences. Macmillan & Creelman (Signal Detection Theory); NASA-TLX background (Hart & Staveland).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nHow to read this policy\n\nPre-onset (t &lt; 30 min): the decision threshold stays at 0.70.\nPost-onset: the threshold relaxes exponentially toward the floor 0.50‚Äîi.e., the system becomes more tolerant of High-Load detections as vigilance degrades.\nMicrobreak (t = 60 min): a small reset tightens the threshold, then decays over ~2 min. (Demo uses a fixed, modest reset.)\nHalf-life: at t = onset + half-life = 30 + 21 = 51 min, the threshold sits halfway between 0.70 and 0.50.\nDesign intent: this is a controller on the criterion‚Äîtransparent, auditable, and tunable per surgeon/task; it does not assume the evidence itself drifts.\n\n\n\n\nWhy a policy like this? Vigilance typically declines with time-on-task while perceived workload rises; brief microbreaks improve comfort and focus without harming flow. Pupil/HRV often show fast, partial recovery over 1‚Äì3 minutes. A time-scheduled, small criterion reset captures these operational realities without heavy modeling.\nGood defaults (to be tuned): onset_min 20‚Äì30 min; fatigue_half_life_min 15‚Äì30 min; reset proportional to observed pre/post microbreak recovery, with decay 1‚Äì3 min.\nReferences.\n\nWarm, Parasuraman & Matthews (2008). Vigilance requires hard mental work and is stressful. Human Factors, 50(3), 433‚Äì441. DOI: 10.1518/001872008X312152\nDorion & Darveau (2013). Do micropauses prevent surgeon‚Äôs fatigue and loss of accuracy? Ann Surg, 257(2), 256‚Äì259. DOI: 10.1097/SLA.0b013e31825efe87\nPark et al.¬†(2017). Intraoperative ‚Äúmicrobreaks‚Äù with exercises reduce surgeons‚Äô musculoskeletal injuries. J Surg Res, 211, 24‚Äì31. DOI: 10.1016/j.jss.2016.11.017\nHallbeck et al.¬†(2017). The impact of intraoperative microbreaks‚Ä¶ Applied Ergonomics, 60, 334‚Äì341. DOI: 10.1016/j.apergo.2016.12.006\nLuger et al.¬†(2023). One-minute rest breaks mitigate healthcare worker stress. JMIR, 25, e44804. DOI: 10.2196/44804\nUnsworth & Robison (2018). Tracking arousal with pupillometry. Cogn Affect Behav Neurosci, 18, 638‚Äì664. DOI: 10.3758/s13415-018-0604-8"
  },
  {
    "objectID": "projects/surgeon-performance-predict2.html#why-thresholds-must-adapt",
    "href": "projects/surgeon-performance-predict2.html#why-thresholds-must-adapt",
    "title": "Surgeon Cognitive Dashboard ‚Äî Case Study",
    "section": "Why thresholds must adapt",
    "text": "Why thresholds must adapt\n\n\n\n  \n    \n    Interactive Training Lab\n  \n  \n    Compare all three threshold policies on the same biosignal stream. Switch policies mid-run, adjust parameters, and export configurations for production use.\n  \n  \n    Adaptive Gain\n    Dual-Criterion\n    Time-on-Task\n  \n  \n    \n      Launch Training Lab\n    \n  \n  Opens in new tab ¬∑ May take a few seconds to load\n\n\n\nSwitch between policies on the same stream. Notice how the same physiologic trace produces different coaching behavior. Policy is a choice, and it should be teachable."
  },
  {
    "objectID": "projects/surgeon-performance-predict2.html#production-dashboard",
    "href": "projects/surgeon-performance-predict2.html#production-dashboard",
    "title": "Surgeon Cognitive Dashboard ‚Äî Case Study",
    "section": "Production Dashboard",
    "text": "Production Dashboard\n\n\nLive Monitor Overview\n\n  \n    \n  \n\n\nComponent Details ‚Äî Zoomable Gallery\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n\nClick any image to zoom and navigate with arrow keys.\n\nML Diagnostics Overview\n\n  \n    \n  \n\n\nML Diagnostics Details ‚Äî Zoomable Gallery"
  },
  {
    "objectID": "projects/surgeon-performance-predict2.html#methods-what-runs-under-the-hood",
    "href": "projects/surgeon-performance-predict2.html#methods-what-runs-under-the-hood",
    "title": "Surgeon Cognitive Dashboard ‚Äî Case Study",
    "section": "Methods (what runs under the hood)",
    "text": "Methods (what runs under the hood)\nData & provenance.\nWe use (a) synthetic sessions produced by the same code paths as the live app (seeded; 10‚Äì30 min, 50‚Äì100 Hz raw) and (b) replayable demo logs exported from the dashboard. All analyses in this page use time-stamped streams (UTC, ms).\nSignals & sampling.\nPupil diameter (mm; eye tracker), HRV from PPG/ECG (ms), grip force (N), tool-tip tremor (Œºm, 8‚Äì12 Hz band), blinks (blinks/min), ambient noise (dB). Signals are synchronized to a common clock and resampled to 10 Hz for feature windows.\nPreprocessing.\n- Pupil: blink interpolation ‚Üí robust z-scoring within session; TEPR = event-locked delta (2‚Äì5 s).\n- HRV: RMSSD computed over rolling 60 s (also 30/120 s for sensitivity); artifact correction via outlier trimming (5√óMAD).\n- Grip/tremor: 2‚Äì10 s rolling mean/SD; tremor via band-pass and RMS.\n- Blink rate: rolling 60 s count; winsorized (1st/99th pct).\nFeatures (examples; all z-scored within session).\n- Pupil: tonic_30s_mean; tepr_5s_delta; pupil_cv_30s.\n- HRV: rmssd_60s; rmssd_slope_60s; rmssd_ma_180s; rmssd√ótepr interaction.\n- Grip/Tremor: grip_mean_15s; grip_cv_15s; tremor_rms_10s; tremor_trend_60s.\n- Ocular: blink_rate_60s; fixation_var_30s.\n- Context: noise_db_30s.\nModeling.\nXGBoost (multi:softprob, 3 classes: Normal / High-Load / Lapse). Class imbalance handled via class weights (rare Lapse upweighted) and PR-AUC monitoring. Lapse probability is calibrated with Platt scaling (logistic on validation folds). We report ECE and Brier.\nThreshold policies (runtime).\n- Adaptive Gain (Inverted-U): keeps evidence within an optimal band.\n- Dual-Criterion (SDT) with hysteresis: two criteria + enter/exit guards.\n- Time-on-Task (Fatigue): hold ‚Üí relax with half-life; microbreak gives a decaying reset.\nValidation.\nLeave-One-Surgeon-Out (LOSO) where available; otherwise session-level 5√ó CV with subject leakage prevented. Hyperparameters chosen by Bayesian search, then frozen.\nReproducibility.\nSeeds fixed; all plots are generated by scripts under scripts/90_make_gallery.R so the case study visuals match the live app implementation."
  },
  {
    "objectID": "projects/surgeon-performance-predict2.html#methods-results-that-matter-ops-kpis",
    "href": "projects/surgeon-performance-predict2.html#methods-results-that-matter-ops-kpis",
    "title": "Surgeon Cognitive Dashboard ‚Äî Case Study",
    "section": "Methods & results that matter (ops KPIs)",
    "text": "Methods & results that matter (ops KPIs)\nWe track outcomes that training leaders can act on:\n\nHigh-load minutes per hour (‚Üì is better). Target ‚â•20‚Äì30% reduction after policy tuning.\nRecovery latency after alerts/microbreaks (‚Üì). Time for HRV/tremor to normalize; aim for &lt;120 s median.\nAlarm burden & acceptance (‚Üò nuisance, ‚Üó adherence). Alerts/hour, % acknowledged, % acted upon.\nStability (‚Üó). Fewer state flips near thresholds with hysteresis vs naive criteria.\nTime-to-proficiency (‚Üò). Sessions to hit competency rubric milestones.\n\nAnalytics: per-session trend lines + bootstrapped CIs; PR-AUC for Lapse, calibration error (ECE), and threshold-level lift curves for explainability."
  },
  {
    "objectID": "projects/surgeon-performance-predict2.html#live-clinical-style-table-with-literature-ranges",
    "href": "projects/surgeon-performance-predict2.html#live-clinical-style-table-with-literature-ranges",
    "title": "Surgeon Cognitive Dashboard ‚Äî Case Study",
    "section": "Live clinical-style table with literature ranges",
    "text": "Live clinical-style table with literature ranges"
  },
  {
    "objectID": "projects/surgeon-performance-predict2.html#product-vs.-lab-how-they-fit",
    "href": "projects/surgeon-performance-predict2.html#product-vs.-lab-how-they-fit",
    "title": "Surgeon Cognitive Dashboard ‚Äî Case Study",
    "section": "Product vs.¬†Lab ‚Äî how they fit",
    "text": "Product vs.¬†Lab ‚Äî how they fit\nThe Lab teaches the concepts and lets instructors tune policy; the Dashboard runs that policy live with guardrails and explains why an alert fired.\n\n\n\n\n\n\n\n\n\n\n\n\n\nProduct vs.¬†Lab ‚Äî how they fit\n\n\nOperational app (left) vs.¬†pedagogy sandbox (right)\n\n\nAspect\nProduction Dashboard\nTraining Lab\n\n\n\n\nPurpose\nReal-time monitoring & decision support\nTheory exploration & threshold policy tuning\n\n\nAudience\nClinicians, safety officers\nEducators, researchers\n\n\nFeatures\nLive gt table, tuned alerts, evidence fusion (pupil + HRV + grip/tremor)\nThree paradigms (Adaptive Gain, SDT+hysteresis, Time-on-Task)\n\n\nLatency\n&lt; 1 s UI; heavier data load\nInstant\n\n\nInteractivity\nThreshold policies runnable; microbreak logging\nSide-by-side policy comparisons; sliders\n\n\nCalibration\nXGBoost + Platt scaling; reliability curve (ECE/Brier)\nNot model-based; exports policy defaults\n\n\nStatus\nStable, no extra wearables UI\nExperimental, fast iteration\n\n\n\nNote. The Lab defines pedagogy & defaults; the Dashboard executes with calibrated probabilities and alert hygiene."
  },
  {
    "objectID": "projects/surgeon-performance-predict2.html#from-sst-to-the-or-what-transferred",
    "href": "projects/surgeon-performance-predict2.html#from-sst-to-the-or-what-transferred",
    "title": "Surgeon Cognitive Dashboard ‚Äî Case Study",
    "section": "From SST to the OR ‚Äî what transferred",
    "text": "From SST to the OR ‚Äî what transferred\n\nAlert hygiene over cleverness. A good model with bad alerting is a bad product. We optimize nuisance rate and edge-chatter, not just AUC.\n\nInterpretability on contact. ‚ÄúHigh-Load confirmed (TEPR‚Üë + RMSSD‚Üì)‚Äù is actionable; a confusion matrix mid-case is not.\n\nFriction kills adoption. Every cable/cap/password taxes attention. That‚Äôs why this stays zero-headgear with &lt;60-second setup."
  },
  {
    "objectID": "projects/surgeon-performance-predict2.html#deployment-privacy",
    "href": "projects/surgeon-performance-predict2.html#deployment-privacy",
    "title": "Surgeon Cognitive Dashboard ‚Äî Case Study",
    "section": "Deployment & Privacy",
    "text": "Deployment & Privacy\nRuns as a Docker image or on ShinyApps; can embed in training portals with a single &lt;iframe&gt;. By default, surgeon biometrics are ephemeral: we retain only de-identified aggregates (for QA/research) with explicit consent. The system is assistive, not autonomous‚Äîthe clinician remains in the loop, with visible rationale for alerts."
  },
  {
    "objectID": "projects/surgeon-performance-predict2.html#whats-next-tailored-pedagogy",
    "href": "projects/surgeon-performance-predict2.html#whats-next-tailored-pedagogy",
    "title": "Surgeon Cognitive Dashboard ‚Äî Case Study",
    "section": "What‚Äôs next ‚Äî tailored pedagogy",
    "text": "What‚Äôs next ‚Äî tailored pedagogy\n\nEstimate the trainee‚Äôs arousal band. Use early sessions to fit a simple sweet-spot width (from TEPR/HRV vs performance), then personalize alert sensitivity.\nPhase-aware coaching. Different thresholds for docking, dissection, suturing; tighten only where error costs are high.\nPost-hoc debriefs. Auto-compile moments of sustained overload (‚â•30 s) with linked video, instructor notes, and the coaching action taken.\nProspective classroom studies. Randomize microbreak timing/pacing advice and measure effects on recovery latency and learning curves.\n\n\n\n\n  What this is / What this isn't\n  \n    ‚úì What this is.\n    A deployable, no body-worn hardware training aid that fuses biosignals with robot telemetry to surface when coaching helps most.\n  \n  \n    ‚úó What this isn't.\n    A medical device or punitive scoring system; it doesn't replace instructor judgment or certify clinical readiness."
  },
  {
    "objectID": "projects/archive/surgeon-performance-predict.html",
    "href": "projects/archive/surgeon-performance-predict.html",
    "title": "The Surgeon‚Äôs ‚ÄòCognitive Black Box‚Äô",
    "section": "",
    "text": "üöÄ The Vision: From Post-Op Review to Proactive Support\n\n‚ÄúDuring my time as an AI Annotator at Surgical Safety Technologies (SST), I had a firsthand view of how their groundbreaking ‚ÄòOR Black Box‚Äô captures the complex dynamics of the operating room to improve patient outcomes. This experience solidified my understanding of the immense value in data-driven clinical insights. It also highlighted the next critical frontier: moving beyond analyzing what happened to understanding the surgeon‚Äôs cognitive state‚Äîthe why behind their actions.‚Äù\n\nThis project is my answer to that challenge. I developed a proof-of-concept for a ‚ÄúCognitive Black Box‚Äù‚Äîan end-to-end analytics platform that predicts a surgeon‚Äôs cognitive state in real-time. By fusing my PhD research on the cognitive neuroscience of effort with my industry experience, this case study demonstrates a tangible solution for moving from post-operative review to proactive, intraoperative support, enhancing both patient safety and surgeon well-being.\n\n\n\n\n\n\n\nA mockup of a surgical console screen displaying a time-series plot of the surgeon‚Äôs pupil dilation and grip force variability, indicating their cognitive state during a procedure.\n\n\n\n\n\nüß† The Scientific Framework: My Research in Action\nThis project is an application of my PhD research, which provides the theoretical engine to model the underlying mechanisms of performance degradation under pressure.\n\nAdaptive Gain Theory (AGT)Resource Competition TheoryKey Concepts & Terminology\n\n\nAGT provides the physiological why. The brain‚Äôs arousal system (specifically the LC-NE system) acts like a ‚Äúvolume knob,‚Äù adjusting neural gain to enhance important signals and suppress noise. My research shows that under the high combined effort typical of surgery, this system can become dysregulated, a phenomenon I can model and predict using pupillometry as a direct, non-invasive biomarker of this process.\n Caption: The inverted-U relationship between arousal and performance, central to Adaptive Gain Theory. My system is designed to identify when a surgeon moves past the optimal point and into a state of impaired performance due to excessive cognitive load.\n\n\nThis framework explains what happens when a surgeon performs a physically demanding action (like sustained retraction, mirroring my 40% MVC research) while making a high-stakes cognitive judgment. These tasks compete for the same finite pool of mental resources. My model is designed to detect when this competition leads to performance-impairing cognitive overload.\n\n\nA brief glossary of the core concepts from my research that power this project.\n\nPupillometry: The measurement of pupil diameter. I use it as a precise, non-invasive biomarker of cognitive effort and arousal, as it is tightly linked to activity in the brain‚Äôs Locus Coeruleus-Norepinephrine (LC-NE) system.\nTonic vs.¬†Phasic Arousal: These are two distinct modes of the arousal system that I model with my features:\n\nTonic Arousal (tonic_pupil_level_30s): Refers to the slow-moving, baseline level of alertness over a longer period (tens of seconds). It reflects the surgeon‚Äôs overall engagement and processing load.\nPhasic Arousal (phasic_pupil_change_5s): Refers to the rapid, transient bursts of arousal in response to a specific event (e.g., making a critical suture). It reflects the momentary deployment of focused mental effort.\n\nGrip Force Variability (grip_force_variability_15s): A novel feature I engineered for this project. It‚Äôs based on the hypothesis that maintaining a steady isometric muscle contraction requires constant attentional control. Therefore, an increase in the variability (i.e., noise) of the grip force signal can serve as a proxy for a lapse in sustained attention.\nXGBoost (Extreme Gradient Boosting): The machine learning algorithm I chose for the classification task. It is a high-performance, industry-standard model known for its accuracy and its ability to handle complex, non-linear relationships in data.\nFeature Engineering: The process of transforming raw sensor data into meaningful variables that machine learning algorithms can use effectively. My domain expertise in cognitive neuroscience guided the creation of theory-driven features rather than generic statistical measures.\nCross-Validation & Hyperparameter Tuning: Rigorous methods to ensure model reliability. Cross-validation tests the model on unseen data subsets, while hyperparameter tuning optimizes the model‚Äôs configuration for best performance.\n\n\n\n\n\n\n\n‚öôÔ∏è The Machine Learning Pipeline: From Raw Data to Actionable Insight\nI designed an end-to-end pipeline to simulate and process multimodal data, engineer theoretically-grounded features, and train a predictive model.\n\n1. Data Simulation2. Feature Engineering3. Modeling & Explainability (XAI)\n\n\nTo build this proof-of-concept, I simulated a realistic, second-by-second data stream from a 3-hour surgical procedure. The dataset includes:\n\nPhysiological Data: pupil_diameter_mm - continuous pupillometry measurements\nMotor Control Data: grip_force_newtons - surgical instrument grip pressure\nBehavioral Data: instrument_tremor_hz- high-frequency tremor measurements\n\nTarget Variable: cognitive_state (‚ÄúOptimal‚Äù, ‚ÄúHigh Load‚Äù, ‚ÄúFatigued‚Äù, ‚ÄúAttentional Lapse‚Äù)\n\nThe simulation creates 32,400 observations (3 surgeons √ó 10,800 seconds) with realistic temporal dynamics and state transitions based on surgical workflow patterns.\n\n\nThis is where my domain expertise becomes critical. I created novel, theory-driven features:\n\ntonic_pupil_level_30s: A 30-second rolling average of pupil diameter, reflecting baseline arousal and overall cognitive load.\nphasic_pupil_change_5s: An event-related dilation metric capturing rapid pupil changes from a 5-second baseline, reflecting the brain‚Äôs adaptive gain response to critical surgical events.\ngrip_force_variability_15s: A novel metric I developed for this project. It calculates the 15-second rolling standard deviation of instrument grip force, based on my hypothesis, grounded in dual-task literature, that increased variability in fine motor control serves as a proxy for attentional lapses.\ntremor_trend_10s: A 10-second rolling mean of instrument tremor, capturing fine motor control degradation.\npupil_diameter_lag_5s: Temporal context feature providing the pupil state from 5 seconds prior.\n\n\n\nI trained an XGBoost Classifier with hyperparameter tuning using 3-fold cross-validation‚Äîan industry-standard, high-performance model‚Äîto predict the surgeon‚Äôs cognitive state. The model achieves:\n\nOverall Accuracy: 99.58%\nCohen‚Äôs Kappa: 0.993\nCross-Validation: Robust performance across folds with grid search optimization\n\nTo ensure the model is interpretable and trustworthy for clinical stakeholders, I implemented feature importance analysis and dynamic explanations that show which physiological signals are driving each prediction in real-time.\n\n\n\n\n\n\n\nFeature importance from the trained XGBoost model showing the relative predictive power of each engineered feature.\n\n\n\n\n\n\n\n\n‚ú® The Result: A Real-Time Analytics Dashboard\nThe final output is a proof-of-concept dashboard built in R Shiny. It simulates a live view of the surgeon‚Äôs cognitive state and provides clear, interpretable alerts with two main interfaces:\n\nLive Surgical DashboardML Model Diagnostics\n\n\nThe primary interface provides real-time monitoring during surgery with an intuitive, clinical-focused design.\n\n\n\n\n\n\n\nLive Surgical Dashboard showing real-time pupil diameter and grip force monitoring with cognitive state prediction and dynamic clinical interpretations.\n\n\nKey Features:\n\nReal-time sensor plots: Pupil diameter and grip force visualized with human-readable time formatting\nCognitive state spectrum: Dynamic dial showing current state on a visual spectrum\nProgress tracking: Video-style progress bar with accurate time remaining\nDynamic ‚ÄúWhy‚Äù panel: Data-driven clinical interpretations that update based on live feature values\nSpeed controls: Simulation can run at 1x, 10x, 50x, or 100x speed for demos\n\n\n\nThe technical interface provides transparency into the machine learning model‚Äôs decision-making process.\n\n\n\n\n\n\n\nML Model Diagnostics panel showing prediction probabilities, live feature values, and feature importance visualization.\n\n\nTechnical Features:\n\nPrediction probabilities: Live confidence scores for all four cognitive states\nFeature values table: Real-time display of all engineered features driving predictions\nFeature importance: Static visualization showing which features matter most to the model\n\n\n\n\nInnovation Highlight: Data-Driven Explanations The most innovative feature is the dynamic ‚ÄúWhy‚Äù panel that doesn‚Äôt just show generic text, but reports the actual feature values driving each prediction (e.g., ‚ÄúHigh Grip Force Variability (2.31 N)‚Äù or ‚ÄúElevated Tonic Pupil Level (4.2 mm)‚Äù), building trust through transparency.\n\n\n\nüöÄ Applications: Enhancing the da Vinci Surgical System\nThe true power of this research is its direct applicability to high-stakes environments. While the methodology is versatile, this case study focuses on a specific, high-impact application: enhancing the capabilities of Intuitive‚Äôs da Vinci surgical systems.\nThe da Vinci platform provides unparalleled robotic control and visualization but currently lacks objective, real-time monitoring of the surgeon‚Äôs cognitive state. My ‚ÄúCognitive Black Box‚Äù is designed to integrate seamlessly with the existing da Vinci ecosystem to fill this critical gap, transforming the surgeon‚Äôs console into a cognitively-aware command center.\n\nüè• High-Stakes Medicine: The Cognitively-Aware Surgical Console\nProblem: A surgeon‚Äôs performance can be compromised by fatigue and high cognitive load long before they are consciously aware of it. The da Vinci system logs instrument data, but it cannot see the surgeon‚Äôs mental state.\nMy Solution: Integrate my real-time cognitive state analytics directly into the da Vinci surgeon console.\n1. Integration with the Surgeon Console Viewfinder:\n\nExisting Feature: The da Vinci surgeon console provides a high-definition, 3D view of the surgical site.\nMy Enhancement: I propose a minimalist Heads-Up Display (HUD) overlay at the edge of the viewfinder. This HUD would display a simple, color-coded Cognitive State Indicator (CSI). It would remain a calm green during ‚ÄúOptimal‚Äù states, turn yellow during ‚ÄúHigh Load,‚Äù and provide a subtle, non-distracting red pulse during a predicted ‚ÄúAttentional Lapse.‚Äù This provides critical feedback without diverting the surgeon‚Äôs focus.\n\n2. Leveraging da Vinci‚Äôs Built-in Data Streams:\n\nExisting Feature: Da Vinci systems can already record instrument and event data. My work at SST involved annotating this type of procedural video data.\nMy Enhancement: My system would tap into these existing data streams. The grip_force_variability feature I developed would be calculated directly from the force sensors in the master controllers (the surgeon‚Äôs hand controls). The phasic_pupil_response would be timed to critical events logged by the system, such as instrument activation or error alerts. This isn‚Äôt a new set of sensors; it‚Äôs a smarter use of the data already being generated.\n\n3. Enhancing Post-Operative Debriefing with ‚ÄúSimulated Eye View‚Äù:\n\nExisting Feature: Intuitive provides products like the ‚ÄúSimulated Eye View‚Äù for post-operative review and training.\nMy Enhancement: I propose augmenting these recordings with a synchronized timeline of the surgeon‚Äôs predicted cognitive state. Trainees could see exactly when and why a period of high cognitive load occurred, correlating it with specific surgical steps. The ‚ÄúWhy‚Äù panel from my dashboard would provide objective, data-driven talking points for the debriefing session, moving beyond subjective recall.\n\n\n\n\n\nüìö Project Artifacts & Technical Details\n\nCode & RepositoryModel PerformanceResearch Foundation\n\n\n\nGitHub Repository: View the complete source code, data pipeline, and interactive dashboard\nTech Stack: R, Shiny, XGBoost, tidyverse, ggplot2, DT\nDevelopment Approach: Modular pipeline with separate scripts for data simulation, feature engineering, and model training\nReproducibility: All code includes seed setting and comprehensive logging for transparent replication\n\n\n\nTraining Results:\n\nDataset: 32,400 observations across 3 simulated surgeons\nFeatures: 5 engineered features from 3 raw sensor streams\nAlgorithm: XGBoost with 3-fold cross-validation hyperparameter tuning\nAccuracy: 99.58% overall accuracy with Œ∫ = 0.993\n\nPer-Class Performance:\n\nOptimal State: 100% sensitivity, 100% specificity\nHigh Load: 99.9% sensitivity, 100% specificity\n\nFatigued: 99.9% sensitivity, 99.4% specificity\nAttentional Lapse: 25% sensitivity, 100% specificity*\n\nAttentional lapses are rare events (0.4% prevalence), where high specificity is prioritized to avoid false alarms.\n\n\n\nGrant Proposal: Read the peer-reviewed research proposal providing the theoretical foundation\nIndustry Context: Inspired by work as AI Annotator at Surgical Safety Technologies (SST)\nAcademic Integration: Direct application of PhD research on cognitive neuroscience of effort and Adaptive Gain Theory\n\n\n\n\n\n\n\nüéØ Impact & Next Steps\nImmediate Applications:\n\nSurgical Training: Objective assessment of trainee cognitive load during skill development, reducing time-to-proficiency and identifying trainees who may require additional support\nQuality Improvement: Data-driven insights into when and why surgical performance degrades, potentially reducing intraoperative errors by flagging high-risk cognitive states\nResearch Platform: Foundational system for studying cognitive load in high-stakes environments\n\nFuture Development:\n\nHardware Integration: Connect with real pupillometry and force sensor systems\nClinical Validation: Partner with surgical training centers for real-world testing\n\nMulti-Modal Expansion: Incorporate additional physiological signals I have experience with, such as Heart Rate Variability (HRV), EEG, and cortisol\nTeam Monitoring: Extend to monitor multiple team members simultaneously\n\nThis proof-of-concept demonstrates the feasibility of real-time cognitive monitoring in surgical environments, bridging fundamental neuroscience research with practical clinical applications.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/dual-task-case-study.html",
    "href": "projects/dual-task-case-study.html",
    "title": "Case Study: A Psychophysiological Approach to Modeling Dual-Task Interference",
    "section": "",
    "text": "‚ÄúImagine an airline pilot mid-flight, gripping the yoke while processing a cascade of system alerts. Or an older surgeon holding robotic instruments while navigating fragile anatomy. In both cases, sustained physical load collides with high cognitive demands‚Äîand performance can slip.‚Äù\n\nIn high-stakes environments, understanding the precise point where a user becomes overwhelmed is critical for safety and efficiency. This case study outlines the research roadmap I designed to objectively measure and predict cognitive overload, moving beyond guesswork to create data-driven solutions for safer, more adaptive systems.\nThe framework combines controlled physical stressors (isometric handgrip), a battery of cognitive tasks, and real-time physiological biomarkers (pupillometry) to deconstruct how performance degrades under real-world pressure."
  },
  {
    "objectID": "projects/dual-task-case-study.html#aerospace-defense",
    "href": "projects/dual-task-case-study.html#aerospace-defense",
    "title": "Case Study: A Psychophysiological Approach to Modeling Dual-Task Interference",
    "section": "‚úàÔ∏è Aerospace & Defense",
    "text": "‚úàÔ∏è Aerospace & Defense\nProblem: Pilots and drone operators must simultaneously manage fine motor control and process complex data streams, where cognitive overload can be catastrophic.\n\nLockheed Martin: Integrate continuous pupillometry into F-35 simulators to compute a live Cognitive Load Index, pinpointing maneuvers that trigger overload and allowing for targeted training to build resilience.\n\n\n\n\n\n\n\n\nA mockup of a pilot‚Äôs heads-up display showing a real-time ‚ÄòCognitive Load‚Äô gauge, derived from pupillometry data.\n\n\n\nGeneral Atomics: Use grip-force calibration and cognitive load testing to redesign Predator drone controls, creating ergonomic interfaces that minimize cognitive interference and free up operator capacity for strategic decision-making.\n\n\n\n\n\n\n\n\nA UI/UX wireframe of a drone operator‚Äôs console, designed with annotations highlighting ergonomic improvements."
  },
  {
    "objectID": "projects/dual-task-case-study.html#high-stakes-medicine",
    "href": "projects/dual-task-case-study.html#high-stakes-medicine",
    "title": "Case Study: A Psychophysiological Approach to Modeling Dual-Task Interference",
    "section": "üè• High-Stakes Medicine",
    "text": "üè• High-Stakes Medicine\nProblem: Surgeons using robotics platforms like the da Vinci system endure prolonged physical strain that can impair the complex decision-making required for patient safety.\n\nIntuitive Surgical: Embed a Dual-Task Performance Dashboard into the surgical console, showing a real-time, pupil-based arousal graph alongside surgical metrics to give surgeons objective feedback on their cognitive state.\n\n\n\n\n\n\n\n\nA mockup of a surgical console screen displaying a time-series plot of the surgeon‚Äôs pupil dilation, indicating cognitive load during a procedure.\n\n\n\nCAE Healthcare: Enhance simulators to score both task precision and cognitive load, identifying fatigue ‚Äúhotspots‚Äù where performance degrades. This allows for more effective training and debriefing.\n\n\n\n\n\n\n\n\nA sample chart showing that as cognitive load (pupil dilation, red dashed line) spikes during high-load events, task accuracy (blue line) decreases."
  },
  {
    "objectID": "projects/dual-task-case-study.html#industry-4.0-human-robot-collaboration",
    "href": "projects/dual-task-case-study.html#industry-4.0-human-robot-collaboration",
    "title": "Case Study: A Psychophysiological Approach to Modeling Dual-Task Interference",
    "section": "üè≠ Industry 4.0 & Human-Robot Collaboration",
    "text": "üè≠ Industry 4.0 & Human-Robot Collaboration\nProblem: As factory workers collaborate more closely with robots, their safety depends on maintaining situational awareness while performing manual tasks.\n\nSiemens / Rockwell Automation: Develop ‚Äúsmart tools‚Äù that sense a worker‚Äôs grip force and use in-helmet eye-tracking to detect cognitive overload. When overload is detected, a nearby collaborative robot could automatically slow down, creating a safer, adaptive manufacturing environment.\n\n\n\n\n\n\n\n\nA concept illustration showing a worker‚Äôs smart tool with embedded sensors providing a real-time data feedback loop to a nearby collaborative robot."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mohammad Dastgheib",
    "section": "",
    "text": "I am a cognitive neuroscientist and human factors researcher who uses psychophysics, pupillometry, and computational modeling to understand how the human brain makes decisions under pressure.\nView my featured case study ‚Üí\n\n    \n    \n  \n\n\n\n\n\n\n\n\nCurrently Seeking Internships\n\n\n\nI am available for Winter 2025 and Summer 2026 internship roles in UX Research, Human Factors, or as a Research Scientist.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "portfolio/index.html",
    "href": "portfolio/index.html",
    "title": "Portfolio",
    "section": "",
    "text": "Welcome to my portfolio. Each case study below provides a detailed walkthrough of a significant research project. You‚Äôll find a mix of results-driven studies and ‚Äúresearch roadmap‚Äù plans that showcase my ability to both architect and execute complex human-centered research.\n\n  Filter by expertise:\n  \n  \n    Research Domains:\n    Human Factors\n    Cognitive Neuroscience\n    Applied Psychology\n    Biomedical Engineering\n  \n  \n  \n    Methodologies:\n    Psychophysiology\n    Pupillometry\n    Experimental Design\n    Mixed Methods\n    EEG\n    Machine Learning\n  \n  \n  \n    Clear All Filters\n  \n\n\n\n\n\n\n\n\n\n\n\nCase Study: A Psychophysiological Approach to Modeling Dual-Task Interference\n\n\nA research roadmap case study on modeling dual-task interference using pupillometry to enhance performance in high-stakes environments.\n\n\n\n\n\n\n\n\n\n\n\n\nCase Study: Optimizing Learning with Cognitive States\n\n\nAn end-to-end mixed-methods study comparing the effects of napping and meditation on declarative and procedural memory consolidation.\n\n\n\n\n\n\n\n\n\n\n\n\nSurgeon Cognitive Dashboard ‚Äî Case Study\n\n\nA proof-of-concept for a real-time analytics platform that uses pupillometry and motor-based metrics to predict a surgeon‚Äôs cognitive state, inspired by my work at Surgical‚Ä¶\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "CV",
    "section": "",
    "text": "Download Full CV (PDF)"
  },
  {
    "objectID": "cv.html#cv",
    "href": "cv.html#cv",
    "title": "CV",
    "section": "",
    "text": "Download Full CV (PDF)"
  }
]